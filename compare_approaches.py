"""
ðŸ“Š Comparaison : Feature Extraction vs Fine-tuning
===================================================

Ce script compare les deux approches :
1. Feature Extraction : Utilisation de BERT prÃ©-entraÃ®nÃ© tel quel
2. Fine-tuning : BERT ajustÃ© sur nos donnÃ©es

Auteur : Ã‰tudiant ENSA Berrechid
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.approach1.sentiment_analyzer import SentimentAnalyzer
from src.approach1.sentiment_finetuner import BERTFineTuner, create_sample_dataset
import time
import pandas as pd


def compare_approaches():
    """
    Compare Feature Extraction vs Fine-tuning.
    """
    print("\n" + "=" * 70)
    print("ðŸ“Š COMPARAISON : FEATURE EXTRACTION VS FINE-TUNING")
    print("=" * 70)
    print()
    
    # Phrases de test
    test_phrases = [
        "Je me sens incroyablement bien aujourd'hui !",
        "La mÃ©ditation m'aide Ã©normÃ©ment",
        "J'ai du mal Ã  dormir",
        "Je me sens complÃ¨tement dÃ©sespÃ©rÃ©",
        "Il fait beau dehors",
        "Mon anxiÃ©tÃ© revient souvent",
        "Je suis fier d'avoir surmontÃ© mes peurs",
        "Je me sens fatiguÃ© et dÃ©motivÃ©"
    ]
    
    # ========================================
    # APPROCHE 1 : FEATURE EXTRACTION
    # ========================================
    
    print("âš¡ APPROCHE 1 : FEATURE EXTRACTION")
    print("-" * 70)
    print("   Utilisation de BERT prÃ©-entraÃ®nÃ© tel quel (pas de fine-tuning)")
    print()
    
    # Charger l'analyseur actuel
    feature_analyzer = SentimentAnalyzer()
    
    # Tester et mesurer le temps
    start_time = time.time()
    feature_results = []
    
    for phrase in test_phrases:
        result = feature_analyzer.analyze(phrase)
        feature_results.append({
            'text': phrase,
            'sentiment': result['sentiment'],
            'confidence': result['confidence']
        })
    
    feature_time = time.time() - start_time
    
    print("âœ… Feature Extraction terminÃ©e")
    print(f"â±ï¸  Temps total : {feature_time:.3f}s")
    print(f"â±ï¸  Temps moyen par phrase : {feature_time/len(test_phrases):.3f}s")
    print()
    
    # ========================================
    # APPROCHE 2 : FINE-TUNING
    # ========================================
    
    print("\nðŸŽ¯ APPROCHE 2 : FINE-TUNING")
    print("-" * 70)
    print("   BERT ajustÃ© sur donnÃ©es de bien-Ãªtre mental")
    print()
    
    # VÃ©rifier si un modÃ¨le fine-tunÃ© existe
    finetuned_path = './models/finetuned_wellbeing'
    
    if not os.path.exists(finetuned_path):
        print("âš ï¸  ModÃ¨le fine-tunÃ© non trouvÃ©. CrÃ©ation en cours...")
        print()
        
        # CrÃ©er et entraÃ®ner
        texts, labels = create_sample_dataset()
        finetuner = BERTFineTuner(output_dir=finetuned_path)
        train_dataset, val_dataset = finetuner.prepare_data(texts, labels)
        finetuner.train(train_dataset, val_dataset, epochs=2, batch_size=4)
    else:
        print("ðŸ“¥ Chargement du modÃ¨le fine-tunÃ© existant...")
        finetuner = BERTFineTuner(output_dir=finetuned_path)
        finetuner.load_finetuned_model(finetuned_path)
    
    # Tester et mesurer le temps
    start_time = time.time()
    finetuned_results = []
    
    for phrase in test_phrases:
        result = finetuner.predict(phrase)
        finetuned_results.append({
            'text': phrase,
            'sentiment': result['sentiment'],
            'confidence': result['confidence']
        })
    
    finetuned_time = time.time() - start_time
    
    print()
    print("âœ… Fine-tuning terminÃ©")
    print(f"â±ï¸  Temps total : {finetuned_time:.3f}s")
    print(f"â±ï¸  Temps moyen par phrase : {finetuned_time/len(test_phrases):.3f}s")
    print()
    
    # ========================================
    # COMPARAISON DES RÃ‰SULTATS
    # ========================================
    
    print("\n" + "=" * 70)
    print("ðŸ“Š COMPARAISON DES RÃ‰SULTATS")
    print("=" * 70)
    print()
    
    # CrÃ©er un DataFrame pour la comparaison
    comparison_data = []
    
    for i, phrase in enumerate(test_phrases):
        comparison_data.append({
            'Phrase': phrase[:40] + "..." if len(phrase) > 40 else phrase,
            'Feature Ext.': feature_results[i]['sentiment'],
            'Conf. FE': f"{feature_results[i]['confidence']:.1%}",
            'Fine-tuning': finetuned_results[i]['sentiment'],
            'Conf. FT': f"{finetuned_results[i]['confidence']:.1%}",
            'Identique': 'âœ…' if feature_results[i]['sentiment'] == finetuned_results[i]['sentiment'] else 'âŒ'
        })
    
    df = pd.DataFrame(comparison_data)
    
    print(df.to_string(index=False))
    print()
    
    # ========================================
    # STATISTIQUES GLOBALES
    # ========================================
    
    print("\n" + "=" * 70)
    print("ðŸ“ˆ STATISTIQUES GLOBALES")
    print("=" * 70)
    print()
    
    # Calculer les statistiques
    same_predictions = sum(1 for i in range(len(test_phrases)) 
                          if feature_results[i]['sentiment'] == finetuned_results[i]['sentiment'])
    
    agreement_rate = same_predictions / len(test_phrases)
    
    avg_conf_feature = sum(r['confidence'] for r in feature_results) / len(feature_results)
    avg_conf_finetuned = sum(r['confidence'] for r in finetuned_results) / len(finetuned_results)
    
    print(f"ðŸ“Š Taux d'accord : {agreement_rate:.1%}")
    print(f"   ({same_predictions}/{len(test_phrases)} prÃ©dictions identiques)")
    print()
    
    print(f"ðŸŽ¯ Confiance moyenne :")
    print(f"   â€¢ Feature Extraction : {avg_conf_feature:.1%}")
    print(f"   â€¢ Fine-tuning : {avg_conf_finetuned:.1%}")
    print()
    
    print(f"â±ï¸  Vitesse d'infÃ©rence :")
    print(f"   â€¢ Feature Extraction : {feature_time/len(test_phrases):.3f}s/phrase")
    print(f"   â€¢ Fine-tuning : {finetuned_time/len(test_phrases):.3f}s/phrase")
    print()
    
    # ========================================
    # RECOMMANDATIONS
    # ========================================
    
    print("\n" + "=" * 70)
    print("ðŸ’¡ RECOMMANDATIONS")
    print("=" * 70)
    print()
    
    print("âš¡ Feature Extraction - Ã€ utiliser si :")
    print("   âœ… Tu veux des rÃ©sultats immÃ©diats")
    print("   âœ… Tu n'as pas de donnÃ©es d'entraÃ®nement")
    print("   âœ… Tu n'as pas de GPU")
    print("   âœ… Performance \"bonne\" suffit (80-85%)")
    print()
    
    print("ðŸŽ¯ Fine-tuning - Ã€ utiliser si :")
    print("   âœ… Tu veux la meilleure prÃ©cision possible")
    print("   âœ… Tu as des donnÃ©es spÃ©cifiques")
    print("   âœ… Tu as accÃ¨s Ã  un GPU")
    print("   âœ… Tu peux investir 1-3h d'entraÃ®nement")
    print()
    
    print("ðŸ† VERDICT :")
    if avg_conf_finetuned > avg_conf_feature:
        diff = (avg_conf_finetuned - avg_conf_feature) * 100
        print(f"   Fine-tuning est {diff:.1f}% plus confiant en moyenne !")
        print("   â†’ RecommandÃ© pour la production")
    else:
        print("   Feature Extraction est suffisant pour ce cas d'usage")
        print("   â†’ RecommandÃ© pour le prototypage")
    print()
    
    print("=" * 70)
    print("âœ… COMPARAISON TERMINÃ‰E")
    print("=" * 70)
    print()


if __name__ == "__main__":
    compare_approaches()
