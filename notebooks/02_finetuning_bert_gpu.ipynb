{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76f8aec",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Installation des dÃ©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4289e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les packages nÃ©cessaires\n",
    "!pip install -q transformers torch accelerate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc28f2",
   "metadata": {},
   "source": [
    "## âœ… VÃ©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66315639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# VÃ©rifier GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   MÃ©moire totale: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âŒ GPU non disponible - Activer le GPU dans Runtime settings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e6d40",
   "metadata": {},
   "source": [
    "## ðŸ“¥ CrÃ©ation du Dataset bien-Ãªtre\n",
    "\n",
    "500 exemples rÃ©partis en 5 classes de sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "def create_wellbeing_dataset(size=500):\n",
    "    \"\"\"\n",
    "    CrÃ©e un dataset Ã©quilibrÃ© de sentiments bien-Ãªtre\n",
    "    \"\"\"\n",
    "    \n",
    "    WELLBEING_EXAMPLES = {\n",
    "        'trÃ¨s nÃ©gatif': [\n",
    "            \"Je veux tout abandonner\", \"Je ne vois pas d'issue\", \"Je suis dÃ©sespÃ©rÃ©\",\n",
    "            \"Je prÃ©fÃ¨re ne pas exister\", \"Je ne mÃ©rite pas de vivre\", \"Je suis un fardeau\",\n",
    "            \"Rien n'a de sens\", \"Je veux disparaÃ®tre\", \"C'est trop pour moi\",\n",
    "            \"Je ne peux plus continuer\", \"Tout est noir\", \"Je suis incapable\",\n",
    "            \"Personne ne m'aime\", \"Je suis perdu\", \"Je veux en finir\",\n",
    "            \"La vie n'a aucune valeur\", \"Je suis un Ã©chec\", \"Je ne vaux rien\",\n",
    "            \"Je suis seul et abandonnÃ©\", \"Tout est inutile\",\n",
    "        ],\n",
    "        'nÃ©gatif': [\n",
    "            \"Je suis triste\", \"Rien n'a d'importance\", \"Je me sens vide\",\n",
    "            \"Je suis stressÃ©\", \"Je suis anxieux\", \"Je me sens mal\",\n",
    "            \"J'ai peur\", \"Je suis dÃ©couragÃ©\", \"Ã‡a ne va pas bien\",\n",
    "            \"Je suis fatiguÃ©\", \"Je ne sais pas quoi faire\", \"Je me sens seul\",\n",
    "            \"C'est trop difficile\", \"Je suis frustrÃ©\", \"Je n'ai pas d'Ã©nergie\",\n",
    "            \"Je suis dÃ©primÃ©\", \"Rien ne me plaÃ®t\", \"Je suis inquiet\",\n",
    "            \"Je doute de moi\", \"C'est dÃ©primant\", \"Je suis submergÃ©\",\n",
    "            \"Tout est compliquÃ©\", \"Je suis affectÃ©\", \"J'ai des pensÃ©es nÃ©gatives\",\n",
    "            \"Ã‡a m'angoisse\",\n",
    "        ],\n",
    "        'neutre': [\n",
    "            \"Bonjour, comment Ã§a va?\", \"Il fait beau dehors\", \"Quelle heure est-il?\",\n",
    "            \"Ã‡a va, et toi?\", \"Qu'est-ce que tu fais?\", \"Je ne sais pas\",\n",
    "            \"C'est normal\", \"C'est juste une journÃ©e ordinaire\", \"Rien de spÃ©cial\",\n",
    "            \"C'est comme d'habitude\", \"Je fais juste passer le temps\", \"C'est banal\",\n",
    "            \"Rien de nouveau\", \"C'est la routine\", \"Pas grand-chose\",\n",
    "            \"Juste Ã§a\", \"C'est Ã§a\", \"Comme d'habitude\",\n",
    "            \"Rien qui change\", \"C'est tout\", \"Je vais bien, merci\",\n",
    "            \"Aucun souci\", \"C'est ok\", \"Pas mal\", \"C'est acceptable\",\n",
    "        ],\n",
    "        'positif': [\n",
    "            \"Ã‡a va plutÃ´t bien\", \"J'ai une bonne journÃ©e\", \"Je suis content\",\n",
    "            \"Je me sens mieux\", \"C'est sympa\", \"J'aime bien\",\n",
    "            \"Je suis fier de moi\", \"J'ai du courage\", \"Je peux le faire\",\n",
    "            \"Ã‡a va s'arranger\", \"J'ai de l'espoir\", \"Je suis motivÃ©\",\n",
    "            \"C'est agrÃ©able\", \"Je me sens bien\", \"J'ai de l'Ã©nergie\",\n",
    "            \"C'est cool\", \"Je suis optimiste\", \"Ã‡a me plaÃ®t\",\n",
    "            \"Je suis confiant\", \"C'est positif\", \"Je me sens fort\",\n",
    "            \"J'ai du potentiel\", \"Ã‡a me fait du bien\", \"Je suis satisfait\",\n",
    "            \"Ã‡a marche bien\",\n",
    "        ],\n",
    "        'trÃ¨s positif': [\n",
    "            \"Je suis heureux!\", \"C'est magnifique!\", \"Je suis aux anges!\",\n",
    "            \"C'est formidable!\", \"Je suis ravi!\", \"C'est incroyable!\",\n",
    "            \"Je suis enthousiaste!\", \"C'est gÃ©nial!\", \"Je suis exubÃ©rant!\",\n",
    "            \"C'est fantastique!\", \"Je suis dÃ©bordant de joie!\", \"C'est merveilleux!\",\n",
    "            \"Je suis dans l'euphorie!\", \"C'est excellent!\", \"Je suis passionnÃ©!\",\n",
    "            \"C'est extraordinaire!\", \"Je suis conquis!\", \"C'est superbe!\",\n",
    "            \"Je suis comblÃ©!\", \"C'est spectaculaire!\", \"Je suis sur un nuage!\",\n",
    "            \"C'est sublime!\", \"Je suis Ã©panoui!\", \"C'est merveilleux!\",\n",
    "            \"Je suis vivant et Ã©nergique!\",\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    dataset = []\n",
    "    label_to_id = {\n",
    "        'trÃ¨s nÃ©gatif': 0, 'nÃ©gatif': 1, 'neutre': 2,\n",
    "        'positif': 3, 'trÃ¨s positif': 4\n",
    "    }\n",
    "    \n",
    "    examples_per_class = size // 5\n",
    "    \n",
    "    for label, examples in WELLBEING_EXAMPLES.items():\n",
    "        if len(examples) >= examples_per_class:\n",
    "            selected = random.sample(examples, examples_per_class)\n",
    "        else:\n",
    "            selected = examples * (examples_per_class // len(examples) + 1)\n",
    "            selected = selected[:examples_per_class]\n",
    "        \n",
    "        for text in selected:\n",
    "            dataset.append({\n",
    "                'text': text,\n",
    "                'label': label,\n",
    "                'label_id': label_to_id[label]\n",
    "            })\n",
    "    \n",
    "    random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "# CrÃ©er le dataset\n",
    "dataset = create_wellbeing_dataset(500)\n",
    "print(f\"âœ… Dataset crÃ©Ã©: {len(dataset)} exemples\")\n",
    "\n",
    "# Statistiques\n",
    "from collections import Counter\n",
    "label_counts = Counter(d['label'] for d in dataset)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"   {label:20s}: {count:3d} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962584f3",
   "metadata": {},
   "source": [
    "## ðŸ“Š Split Train/Validation (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/val\n",
    "split_idx = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset[:split_idx]\n",
    "val_dataset = dataset[split_idx:]\n",
    "\n",
    "train_texts = [d['text'] for d in train_dataset]\n",
    "train_labels = [d['label_id'] for d in train_dataset]\n",
    "\n",
    "val_texts = [d['text'] for d in val_dataset]\n",
    "val_labels = [d['label_id'] for d in val_dataset]\n",
    "\n",
    "print(f\"âœ… Train: {len(train_texts)} exemples\")\n",
    "print(f\"âœ… Validation: {len(val_texts)} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4dc1a",
   "metadata": {},
   "source": [
    "## ðŸ¤– CrÃ©ation du Dataset PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WellbeingDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"âœ… Classe WellbeingDataset crÃ©Ã©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f205743",
   "metadata": {},
   "source": [
    "## ðŸ”§ Chargement du modÃ¨le BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = 'bert-base-multilingual-uncased'\n",
    "\n",
    "print(f\"ðŸ“¥ Chargement de {model_name}...\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"âœ… Tokenizer chargÃ©\")\n",
    "\n",
    "# ModÃ¨le (5 labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=5\n",
    ")\n",
    "print(\"âœ… ModÃ¨le BERT chargÃ© (110M paramÃ¨tres)\")\n",
    "\n",
    "# Placer sur GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f\"âœ… ModÃ¨le sur: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531f2ef",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ PrÃ©paration des datasets PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44262cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er les datasets\n",
    "train_pytorch_dataset = WellbeingDataset(train_texts, train_labels, tokenizer)\n",
    "val_pytorch_dataset = WellbeingDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "print(f\"âœ… Train dataset: {len(train_pytorch_dataset)} exemples\")\n",
    "print(f\"âœ… Val dataset: {len(val_pytorch_dataset)} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc9f67",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Configuration de l'entraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea93a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert_finetuned',\n",
    "    num_train_epochs=3,              # 3 epochs\n",
    "    per_device_train_batch_size=16,  # Batch 16 sur GPU\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,              # Learning rate standard\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    logging_steps=10,\n",
    "    seed=42,\n",
    "    fp16=True,                       # Mixed precision sur GPU\n",
    ")\n",
    "\n",
    "print(\"âœ… Configuration prÃªte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acd346",
   "metadata": {},
   "source": [
    "## ðŸš€ LANCER L'ENTRAÃŽNEMENT\n",
    "\n",
    "**DurÃ©e estimÃ©e: 2-3 minutes avec GPU T4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34197a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er le Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_pytorch_dataset,\n",
    "    eval_dataset=val_pytorch_dataset,\n",
    ")\n",
    "\n",
    "print(\"ðŸ”¥ LANCEMENT DU FINE-TUNING...\\n\")\n",
    "\n",
    "# ENTRAÃŽNER\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nâœ… ENTRAÃŽNEMENT TERMINÃ‰!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1778f5",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Sauvegarder le modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74822f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder\n",
    "output_dir = './bert_finetuned_final'\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"âœ… ModÃ¨le sauvegardÃ© dans: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97e592",
   "metadata": {},
   "source": [
    "## ðŸ§ª Tester le modÃ¨le fine-tunÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prÃ©diction\n",
    "SENTIMENT_MAP = {\n",
    "    0: 'trÃ¨s nÃ©gatif',\n",
    "    1: 'nÃ©gatif',\n",
    "    2: 'neutre',\n",
    "    3: 'positif',\n",
    "    4: 'trÃ¨s positif'\n",
    "}\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    predicted_id = torch.argmax(probabilities).item()\n",
    "    confidence = probabilities[0, predicted_id].item()\n",
    "    \n",
    "    return {\n",
    "        'sentiment': SENTIMENT_MAP[predicted_id],\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "# Tests\n",
    "test_phrases = [\n",
    "    \"Je suis heureux!\",\n",
    "    \"Je me sens dÃ©primÃ©\",\n",
    "    \"Comment Ã§a va?\",\n",
    "    \"Je ne veux plus continuer\",\n",
    "    \"C'est magnifique!\",\n",
    "    \"Je suis trÃ¨s stressÃ©\",\n",
    "    \"Tout va bien\",\n",
    "    \"Je suis dÃ©sespÃ©rÃ©\",\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“Š TESTS DU MODÃˆLE FINE-TUNÃ‰\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for phrase in test_phrases:\n",
    "    result = predict(phrase)\n",
    "    emoji_map = {\n",
    "        'trÃ¨s nÃ©gatif': 'ðŸ”´',\n",
    "        'nÃ©gatif': 'ðŸŸ ',\n",
    "        'neutre': 'ðŸŸ¡',\n",
    "        'positif': 'ðŸŸ¢',\n",
    "        'trÃ¨s positif': 'ðŸŸ¢ðŸŸ¢'\n",
    "    }\n",
    "    emoji = emoji_map[result['sentiment']]\n",
    "    print(f\"{emoji} '{phrase}'\")\n",
    "    print(f\"   â†’ {result['sentiment']:15s} ({result['confidence']:.1%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d2daf",
   "metadata": {},
   "source": [
    "## ðŸ“¥ TÃ©lÃ©charger le modÃ¨le\n",
    "\n",
    "Compresse le modÃ¨le pour le tÃ©lÃ©charger sur votre ordinateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compresser le modÃ¨le\n",
    "!zip -r bert_finetuned_final.zip bert_finetuned_final/\n",
    "\n",
    "print(\"âœ… ModÃ¨le compressÃ©: bert_finetuned_final.zip\")\n",
    "print(\"\\nðŸ“¥ TÃ©lÃ©charger avec:\")\n",
    "print(\"   - Clic droit sur le fichier dans l'explorateur Colab\")\n",
    "print(\"   - Ou utiliser Google Drive pour le sauvegarder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef3229",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Sauvegarder sur Google Drive (Optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01335ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copier le modÃ¨le\n",
    "!cp -r bert_finetuned_final /content/drive/MyDrive/\n",
    "\n",
    "print(\"âœ… ModÃ¨le sauvegardÃ© sur Google Drive: MyDrive/bert_finetuned_final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53c993",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ TERMINÃ‰!\n",
    "\n",
    "**Prochaines Ã©tapes:**\n",
    "1. TÃ©lÃ©charger le modÃ¨le (`bert_finetuned_final.zip`)\n",
    "2. Extraire dans `models/approach3/bert_finetuned/`\n",
    "3. Tester avec `python compare_approaches.py`\n",
    "\n",
    "**RÃ©sumÃ©:**\n",
    "- âœ… BERT fine-tunÃ© sur 500 exemples bien-Ãªtre\n",
    "- âœ… 5 classes de sentiments\n",
    "- âœ… EntraÃ®nement GPU ~2-3 minutes\n",
    "- âœ… ModÃ¨le prÃªt pour production"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
