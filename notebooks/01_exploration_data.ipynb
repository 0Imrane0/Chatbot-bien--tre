{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676d1a4d",
   "metadata": {},
   "source": [
    "## 1. Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ajouter le chemin du projet\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"‚úÖ Configuration termin√©e !\")\n",
    "print(f\"üìÅ Projet racine : {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6466ff",
   "metadata": {},
   "source": [
    "## 2. Chargement des Composants du Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d90e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les modules du chatbot\n",
    "from src.approach1.sentiment_analyzer import SentimentAnalyzer\n",
    "from src.approach1.mood_tracker import MoodTracker\n",
    "\n",
    "# Initialiser les composants\n",
    "print(\"üîÑ Chargement des composants...\")\n",
    "analyzer = SentimentAnalyzer()\n",
    "tracker = MoodTracker()\n",
    "print(\"‚úÖ Composants charg√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cee31d",
   "metadata": {},
   "source": [
    "## 3. Exploration de l'Historique d'Humeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et afficher l'historique\n",
    "history = tracker.mood_history\n",
    "\n",
    "print(f\"üìä Nombre total de messages : {len(history)}\")\n",
    "\n",
    "if history:\n",
    "    # Convertir en DataFrame pour l'analyse\n",
    "    df = pd.DataFrame(history)\n",
    "    print(\"\\nüìã Aper√ßu des donn√©es :\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nüìä Statistiques descriptives :\")\n",
    "    display(df.describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun historique disponible. Cr√©ons des donn√©es de test...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b2359",
   "metadata": {},
   "source": [
    "## 4. G√©n√©ration de Donn√©es de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases de test pour l'analyse\n",
    "test_phrases = [\n",
    "    # Positif\n",
    "    \"Je suis vraiment heureux aujourd'hui !\",\n",
    "    \"Quelle belle journ√©e, je me sens en forme !\",\n",
    "    \"J'ai r√©ussi mon examen, c'est g√©nial !\",\n",
    "    \"Merci beaucoup, √ßa m'a fait du bien !\",\n",
    "    \"Je me sens √©panoui et confiant !\",\n",
    "    \n",
    "    # N√©gatif\n",
    "    \"Je me sens triste et fatigu√©...\",\n",
    "    \"Cette journ√©e est vraiment difficile.\",\n",
    "    \"Je suis stress√© par le travail.\",\n",
    "    \"Je me sens seul et incompris.\",\n",
    "    \"Rien ne va comme je veux...\",\n",
    "    \n",
    "    # Neutre\n",
    "    \"Il fait beau dehors.\",\n",
    "    \"Je viens de me r√©veiller.\",\n",
    "    \"C'est l'heure du d√©jeuner.\",\n",
    "    \"J'ai lu un livre hier.\",\n",
    "    \"Je vais faire des courses.\"\n",
    "]\n",
    "\n",
    "# Analyser toutes les phrases\n",
    "results = []\n",
    "for phrase in test_phrases:\n",
    "    result = analyzer.analyze(phrase)\n",
    "    results.append({\n",
    "        'text': phrase,\n",
    "        'sentiment': result['sentiment'],\n",
    "        'confidence': result['confidence'],\n",
    "        'predicted_class': result['predicted_class']\n",
    "    })\n",
    "\n",
    "# Cr√©er le DataFrame\n",
    "df_test = pd.DataFrame(results)\n",
    "print(f\"‚úÖ {len(results)} phrases analys√©es !\")\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ddd1e8",
   "metadata": {},
   "source": [
    "## 5. Distribution des Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeea33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique en camembert de la distribution\n",
    "sentiment_counts = df_test['sentiment'].value_counts()\n",
    "\n",
    "colors = {\n",
    "    'tr√®s positif': '#4CAF50',\n",
    "    'positif': '#8BC34A',\n",
    "    'neutre': '#FFC107',\n",
    "    'n√©gatif': '#FF9800',\n",
    "    'tr√®s n√©gatif': '#F44336'\n",
    "}\n",
    "\n",
    "fig = px.pie(\n",
    "    values=sentiment_counts.values,\n",
    "    names=sentiment_counts.index,\n",
    "    title='üéØ Distribution des Sentiments',\n",
    "    color=sentiment_counts.index,\n",
    "    color_discrete_map=colors,\n",
    "    hole=0.4\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='inside',\n",
    "    textinfo='percent+label'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(size=14),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78248f23",
   "metadata": {},
   "source": [
    "## 6. Confiance par Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot de la confiance par sentiment\n",
    "fig = px.box(\n",
    "    df_test,\n",
    "    x='sentiment',\n",
    "    y='confidence',\n",
    "    color='sentiment',\n",
    "    color_discrete_map=colors,\n",
    "    title='üìä Distribution de la Confiance par Sentiment'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Sentiment',\n",
    "    yaxis_title='Confiance',\n",
    "    yaxis=dict(tickformat='.0%'),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78319e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques de confiance par sentiment\n",
    "confidence_stats = df_test.groupby('sentiment')['confidence'].agg(['mean', 'std', 'min', 'max'])\n",
    "confidence_stats.columns = ['Moyenne', '√âcart-type', 'Min', 'Max']\n",
    "confidence_stats = confidence_stats.round(3)\n",
    "\n",
    "print(\"üìà Statistiques de Confiance par Sentiment :\")\n",
    "display(confidence_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bbb26",
   "metadata": {},
   "source": [
    "## 7. Analyse de la Longueur des Textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la longueur du texte\n",
    "df_test['text_length'] = df_test['text'].str.len()\n",
    "df_test['word_count'] = df_test['text'].str.split().str.len()\n",
    "\n",
    "# Scatter plot : longueur vs confiance\n",
    "fig = px.scatter(\n",
    "    df_test,\n",
    "    x='text_length',\n",
    "    y='confidence',\n",
    "    color='sentiment',\n",
    "    color_discrete_map=colors,\n",
    "    size='word_count',\n",
    "    hover_data=['text'],\n",
    "    title='üîç Relation Longueur du Texte vs Confiance'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Longueur du texte (caract√®res)',\n",
    "    yaxis_title='Confiance',\n",
    "    yaxis=dict(tickformat='.0%')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c957c01",
   "metadata": {},
   "source": [
    "## 8. Test de Performances du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Mesurer le temps d'analyse\n",
    "test_texts = [\n",
    "    \"Court texte.\",\n",
    "    \"Ceci est un texte de longueur moyenne pour tester les performances.\",\n",
    "    \"Ceci est un texte beaucoup plus long qui contient de nombreux mots et devrait prendre plus de temps √† analyser car le mod√®le BERT doit traiter plus de tokens. Nous voulons voir comment le temps d'analyse √©volue avec la longueur du texte.\"\n",
    "]\n",
    "\n",
    "performance_results = []\n",
    "\n",
    "for text in test_texts:\n",
    "    start_time = time.time()\n",
    "    result = analyzer.analyze(text)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    performance_results.append({\n",
    "        'text_length': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'time_ms': elapsed_time * 1000,\n",
    "        'sentiment': result['sentiment'],\n",
    "        'confidence': result['confidence']\n",
    "    })\n",
    "\n",
    "df_perf = pd.DataFrame(performance_results)\n",
    "print(\"‚è±Ô∏è Performances d'analyse :\")\n",
    "display(df_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ef9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique de performance\n",
    "fig = px.bar(\n",
    "    df_perf,\n",
    "    x='word_count',\n",
    "    y='time_ms',\n",
    "    color='sentiment',\n",
    "    color_discrete_map=colors,\n",
    "    title='‚è±Ô∏è Temps d\\'Analyse vs Nombre de Mots',\n",
    "    labels={'word_count': 'Nombre de mots', 'time_ms': 'Temps (ms)'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfd770",
   "metadata": {},
   "source": [
    "## 9. Matrice de Confusion (Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1811459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler des pr√©dictions attendues vs r√©elles\n",
    "expected_sentiments = [\n",
    "    'tr√®s positif', 'positif', 'tr√®s positif', 'positif', 'positif',\n",
    "    'n√©gatif', 'n√©gatif', 'n√©gatif', 'tr√®s n√©gatif', 'n√©gatif',\n",
    "    'neutre', 'neutre', 'neutre', 'neutre', 'neutre'\n",
    "]\n",
    "\n",
    "# Comparer avec les pr√©dictions\n",
    "df_test['expected'] = expected_sentiments\n",
    "df_test['correct'] = df_test['sentiment'] == df_test['expected']\n",
    "\n",
    "accuracy = df_test['correct'].mean()\n",
    "print(f\"üìä Pr√©cision globale : {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b465de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er la matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simplifier en 3 cat√©gories\n",
    "def simplify_sentiment(s):\n",
    "    if 'positif' in s.lower():\n",
    "        return 'positif'\n",
    "    elif 'n√©gatif' in s.lower():\n",
    "        return 'n√©gatif'\n",
    "    else:\n",
    "        return 'neutre'\n",
    "\n",
    "df_test['simple_expected'] = df_test['expected'].apply(simplify_sentiment)\n",
    "df_test['simple_predicted'] = df_test['sentiment'].apply(simplify_sentiment)\n",
    "\n",
    "# Matrice de confusion\n",
    "labels = ['positif', 'neutre', 'n√©gatif']\n",
    "cm = confusion_matrix(\n",
    "    df_test['simple_expected'],\n",
    "    df_test['simple_predicted'],\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "# Visualiser avec plotly\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    labels=dict(x=\"Pr√©dit\", y=\"R√©el\", color=\"Nombre\"),\n",
    "    x=labels,\n",
    "    y=labels,\n",
    "    title='üéØ Matrice de Confusion (Simplifi√©e)',\n",
    "    color_continuous_scale='Blues',\n",
    "    text_auto=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52defb",
   "metadata": {},
   "source": [
    "## 10. Simulation d'√âvolution d'Humeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler une semaine de donn√©es\n",
    "import random\n",
    "\n",
    "# G√©n√©rer des donn√©es sur 7 jours\n",
    "simulation_data = []\n",
    "base_date = datetime.now() - timedelta(days=7)\n",
    "\n",
    "sentiments_weights = {\n",
    "    0: 0.1,  # tr√®s n√©gatif\n",
    "    1: 0.2,  # n√©gatif\n",
    "    2: 0.3,  # neutre\n",
    "    3: 0.3,  # positif\n",
    "    4: 0.1   # tr√®s positif\n",
    "}\n",
    "\n",
    "sentiment_names = ['tr√®s n√©gatif', 'n√©gatif', 'neutre', 'positif', 'tr√®s positif']\n",
    "\n",
    "for day in range(7):\n",
    "    # 3-5 messages par jour\n",
    "    num_messages = random.randint(3, 5)\n",
    "    \n",
    "    for msg in range(num_messages):\n",
    "        # Tendance : am√©lioration progressive\n",
    "        day_bias = day * 0.1  # Plus le jour avance, plus c'est positif\n",
    "        \n",
    "        # Choisir un sentiment avec biais\n",
    "        weights = [w + day_bias if i >= 2 else w - day_bias/2 \n",
    "                   for i, w in sentiments_weights.items()]\n",
    "        weights = [max(0.01, w) for w in weights]\n",
    "        weights = [w/sum(weights) for w in weights]\n",
    "        \n",
    "        sentiment_idx = random.choices(range(5), weights=weights)[0]\n",
    "        sentiment = sentiment_names[sentiment_idx]\n",
    "        \n",
    "        # Score de confiance\n",
    "        confidence = random.uniform(0.5, 0.95)\n",
    "        \n",
    "        # Timestamp\n",
    "        timestamp = base_date + timedelta(\n",
    "            days=day,\n",
    "            hours=random.randint(8, 22),\n",
    "            minutes=random.randint(0, 59)\n",
    "        )\n",
    "        \n",
    "        simulation_data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'day': day + 1,\n",
    "            'sentiment': sentiment,\n",
    "            'sentiment_score': sentiment_idx / 4,  # 0 √† 1\n",
    "            'confidence': confidence\n",
    "        })\n",
    "\n",
    "df_sim = pd.DataFrame(simulation_data)\n",
    "print(f\"‚úÖ {len(df_sim)} messages simul√©s sur 7 jours\")\n",
    "display(df_sim.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed140355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'√©volution\n",
    "fig = px.line(\n",
    "    df_sim,\n",
    "    x='timestamp',\n",
    "    y='sentiment_score',\n",
    "    color='sentiment',\n",
    "    color_discrete_map=colors,\n",
    "    title='üìà √âvolution de l\\'Humeur sur 7 Jours',\n",
    "    markers=True\n",
    ")\n",
    "\n",
    "# Ajouter une ligne de tendance\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_sim['timestamp'],\n",
    "    y=df_sim['sentiment_score'].rolling(window=3, min_periods=1).mean(),\n",
    "    mode='lines',\n",
    "    name='Tendance (moyenne mobile)',\n",
    "    line=dict(color='black', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Score d\\'humeur',\n",
    "    yaxis=dict(tickformat='.0%', range=[0, 1])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne par jour\n",
    "daily_avg = df_sim.groupby('day').agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'confidence': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Score d\\'Humeur Moyen par Jour', 'Confiance Moyenne par Jour')\n",
    ")\n",
    "\n",
    "# Score d'humeur\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=daily_avg['day'],\n",
    "        y=daily_avg['sentiment_score'],\n",
    "        marker_color='lightseagreen',\n",
    "        name='Score humeur'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Confiance\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=daily_avg['day'],\n",
    "        y=daily_avg['confidence'],\n",
    "        marker_color='coral',\n",
    "        name='Confiance'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='üìä Statistiques Journali√®res',\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b90f51",
   "metadata": {},
   "source": [
    "## 11. R√©sum√© et Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d719222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© final\n",
    "print(\"=\"*60)\n",
    "print(\"üìä R√âSUM√â DE L'EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìù Donn√©es analys√©es :\")\n",
    "print(f\"   ‚Ä¢ Phrases de test : {len(df_test)}\")\n",
    "print(f\"   ‚Ä¢ Simulation 7 jours : {len(df_sim)} messages\")\n",
    "\n",
    "print(f\"\\nüéØ Performances du mod√®le :\")\n",
    "print(f\"   ‚Ä¢ Pr√©cision (test) : {accuracy:.1%}\")\n",
    "print(f\"   ‚Ä¢ Confiance moyenne : {df_test['confidence'].mean():.1%}\")\n",
    "\n",
    "print(f\"\\nüìà Tendances (simulation) :\")\n",
    "start_score = daily_avg['sentiment_score'].iloc[0]\n",
    "end_score = daily_avg['sentiment_score'].iloc[-1]\n",
    "improvement = (end_score - start_score) / start_score * 100\n",
    "print(f\"   ‚Ä¢ Score d√©but : {start_score:.1%}\")\n",
    "print(f\"   ‚Ä¢ Score fin : {end_score:.1%}\")\n",
    "print(f\"   ‚Ä¢ Am√©lioration : {improvement:+.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Exploration termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c153e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "Ce notebook montre :\n",
    "1. Comment analyser les performances du mod√®le BERT\n",
    "2. La distribution des sentiments d√©tect√©s\n",
    "3. L'√©volution de l'humeur dans le temps\n",
    "4. Les m√©triques de confiance\n",
    "\n",
    "**Prochaines √©tapes :**\n",
    "- Collecter plus de donn√©es r√©elles\n",
    "- Comparer avec l'Approche 2 (mod√®le custom)\n",
    "- Analyser les cas d'erreur\n",
    "\n",
    "---\n",
    "\n",
    "*Projet Chatbot Bien-√™tre - ENSA Berrechid*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
