# ðŸ¤– Prompt pour GitHub Copilot Pro - Chatbot de Bien-Ãªtre (V2 - MISE Ã€ JOUR)

## ðŸ“‹ CONTEXTE DU PROJET

Je suis Ã©tudiant ingÃ©nieur en IngÃ©nierie des SystÃ¨mes d'Information et Big Data Ã  l'ENSA Berrechid. Je dois rÃ©aliser un projet de **Chatbot de Bien-Ãªtre et d'Humeur** dans le cadre de mon module "Programmation Python et IA".

**Objectif :** CrÃ©er un chatbot conversationnel qui :
- Analyse le sentiment des messages utilisateur
- Suit l'Ã©volution de l'humeur dans le temps
- Donne des conseils personnalisÃ©s
- Maintient une conversation empathique

**Important :** Je veux **comprendre** chaque Ã©tape, pas seulement avoir le code. Je veux apprendre en construisant !

---

## ðŸŽ¯ INSTRUCTIONS POUR COPILOT

### Principes Ã  respecter :

1. **Approche pÃ©dagogique** : Explique-moi CHAQUE concept avant de coder
2. **Progression Ã©tape par Ã©tape** : Ne passe Ã  l'Ã©tape suivante qu'aprÃ¨s mon approbation
3. **Code commentÃ©** : Chaque ligne importante doit avoir un commentaire explicatif
4. **Questions de comprÃ©hension** : Pose-moi des questions pour vÃ©rifier ma comprÃ©hension
5. **Trois implÃ©mentations complÃ¨tes** :
   - **Approche 1** : ModÃ¨le prÃ©-entraÃ®nÃ© BERT (Feature Extraction) - âœ… COMPLÃ‰TÃ‰E
   - **Approche 3** : Fine-tuning de BERT sur donnÃ©es bien-Ãªtre - Ã€ FAIRE (PRIORITAIRE)
   - **Approche 2** : ModÃ¨le custom LSTM/GRU - Ã€ FAIRE (ensuite)

---

## ðŸ“Š STATUT DU PROJET (13 Janvier 2026)

### âœ… APPROCHE 1 - COMPLÃ‰TÃ‰E Ã€ 100%
```
PHASE 1-6 : TERMINÃ‰E
âœ… Sentiment Analyzer (BERT Feature Extraction)
âœ… Mood Tracker (historique + tendances)
âœ… Response Generator (rÃ©ponses empathiques)
âœ… Mood Visualizer (graphiques Plotly)
âœ… Interface Web Streamlit
âœ… Interface Console
âœ… 23 tests unitaires (TOUS PASSANTS)
âœ… Documentation complÃ¨te
```

### ðŸ”¥ APPROCHE 3 - PRIORITAIRE (Ã€ FAIRE)
```
PHASE 3B : Ã€ COMMENCER
[ ] Fine-tuning BERT sur donnÃ©es bien-Ãªtre
[ ] DonnÃ©es d'entraÃ®nement
[ ] EntraÃ®nement & sauvegarde
[ ] Comparaison avec Approche 1
[ ] Tests & intÃ©gration
```

### ðŸš€ APPROCHE 2 - FUTURE (Ã€ FAIRE APRÃˆS APPROCHE 3)
```
PHASE 7-12 : Ã€ FAIRE APRÃˆS APPROCHE 3
[ ] Data Preparation
[ ] Model Builder (LSTM/GRU)
[ ] Model Trainer
[ ] Integration
[ ] Tests
```

---

## ðŸ—‚ï¸ STRUCTURE DU PROJET (MISE Ã€ JOUR)

```
Chatbot bien-Ãªtre/
â”‚
â”œâ”€â”€ data/                          # DonnÃ©es et historiques
â”‚   â”œâ”€â”€ mood_history.json          # Suivi de l'humeur (tous utilisateurs)
â”‚   â”œâ”€â”€ mood_test.json             # DonnÃ©es de test
â”‚   â”œâ”€â”€ training_wellbeing_data.json  # DonnÃ©es pour fine-tuning (Approche 3)
â”‚   â””â”€â”€ training_data.csv          # DonnÃ©es pour modÃ¨le custom (Approche 2)
â”‚
â”œâ”€â”€ models/                        # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ approach1/                 # Approche 1 : BERT PrÃ©-entraÃ®nÃ©
â”‚   â”‚   â””â”€â”€ bert_pretrained/       # BERT original (depuis HuggingFace)
â”‚   â”‚
â”‚   â”œâ”€â”€ approach3/                 # Approche 3 : BERT Fine-tunÃ©
â”‚   â”‚   â””â”€â”€ bert_finetuned/        # BERT ajustÃ© sur donnÃ©es bien-Ãªtre
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚       â””â”€â”€ tokenizer files
â”‚   â”‚
â”‚   â””â”€â”€ approach2/                 # Approche 2 : Custom LSTM/GRU
â”‚       â”œâ”€â”€ lstm_model.h5
â”‚       â””â”€â”€ preprocessor.pkl
â”‚
â”œâ”€â”€ src/                           # Code source
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ approach1/                 # âœ… Approche 1 : Feature Extraction (COMPLÃ‰TÃ‰E)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py  # Utilise BERT prÃ©-entraÃ®nÃ© (gelÃ©)
â”‚   â”‚   â”œâ”€â”€ mood_tracker.py        # Suivi de l'humeur
â”‚   â”‚   â”œâ”€â”€ response_generator.py  # GÃ©nÃ©ration de rÃ©ponses
â”‚   â”‚   â”œâ”€â”€ mood_visualizer.py     # Graphiques Plotly
â”‚   â”‚   â”œâ”€â”€ chatbot.py             # Orchestrateur principal
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â””â”€â”€ mood_history.json  # Historique utilisateur
â”‚   â”‚
â”‚   â”œâ”€â”€ approach3/                 # ðŸ”¥ Approche 3 : Fine-tuning BERT (Ã€ FAIRE)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sentiment_finetuner.py # EntraÃ®nement BERT (NOUVEAU)
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py  # Analyse avec BERT fine-tunÃ©
â”‚   â”‚   â”œâ”€â”€ mood_tracker.py        # Suivi (rÃ©utilisÃ© d'Approche 1)
â”‚   â”‚   â”œâ”€â”€ response_generator.py  # RÃ©ponses (rÃ©utilisÃ© d'Approche 1)
â”‚   â”‚   â”œâ”€â”€ mood_visualizer.py     # Graphiques (rÃ©utilisÃ© d'Approche 1)
â”‚   â”‚   â”œâ”€â”€ chatbot.py             # Orchestrateur
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â””â”€â”€ training_wellbeing_data.json
â”‚   â”‚
â”‚   â””â”€â”€ approach2/                 # ðŸš€ Approche 2 : Custom LSTM/GRU (Ã€ FAIRE APRÃˆS)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_preparation.py    # PrÃ©paration des donnÃ©es
â”‚       â”œâ”€â”€ model_builder.py       # Construction du rÃ©seau LSTM
â”‚       â”œâ”€â”€ model_trainer.py       # EntraÃ®nement
â”‚       â”œâ”€â”€ sentiment_analyzer.py  # Analyse avec modÃ¨le custom
â”‚       â”œâ”€â”€ mood_tracker.py        # Suivi (rÃ©utilisÃ©)
â”‚       â”œâ”€â”€ response_generator.py  # RÃ©ponses (rÃ©utilisÃ©)
â”‚       â”œâ”€â”€ mood_visualizer.py     # Graphiques (rÃ©utilisÃ©)
â”‚       â”œâ”€â”€ chatbot.py             # Orchestrateur
â”‚       â””â”€â”€ data/
â”‚           â””â”€â”€ training_data.csv  # DonnÃ©es pour entraÃ®nement
â”‚
â”œâ”€â”€ tests/                         # Tests unitaires
â”‚   â”œâ”€â”€ test_approach1.py          # âœ… Tests Approche 1 (23 tests PASSANTS)
â”‚   â”œâ”€â”€ test_approach3.py          # Tests Approche 3 (Ã€ CRÃ‰ER)
â”‚   â””â”€â”€ test_approach2.py          # Tests Approche 2 (Ã€ CRÃ‰ER)
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (exploration)
â”‚   â”œâ”€â”€ 01_exploration_data.ipynb  # Exploration donnÃ©es
â”‚   â”œâ”€â”€ 02_finetuning_bert.ipynb   # Fine-tuning analysis (Ã€ CRÃ‰ER)
â”‚   â”œâ”€â”€ 03_model_comparison.ipynb  # Comparaison 3 approches (Ã€ CRÃ‰ER)
â”‚   â””â”€â”€ 04_analysis_results.ipynb  # RÃ©sultats finaux (Ã€ CRÃ‰ER)
â”‚
â”œâ”€â”€ ui/                            # Interfaces utilisateur
â”‚   â”œâ”€â”€ console_ui.py              # Interface console
â”‚   â””â”€â”€ streamlit_ui.py            # Interface web (dÃ©jÃ  fonctionnelle)
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ copilot-prompt.md          # Prompt original (CE FICHIER)
â”‚   â””â”€â”€ rapport.md                 # Rapport du projet
â”‚
â”œâ”€â”€ .git/                          # Version control
â”œâ”€â”€ .gitignore                     # Fichiers Ã  ignorer
â”œâ”€â”€ venv/                          # Environnement virtuel Python
â”œâ”€â”€ launch_menu.bat                # Lanceur unique (Windows)
â”œâ”€â”€ main.py                        # Point d'entrÃ©e principal
â”œâ”€â”€ compare_approaches.py          # Comparaison des 3 approches
â”œâ”€â”€ config.yaml                    # Configuration globale
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ setup_nltk.py                  # Configuration NLTK
â”œâ”€â”€ README.md                      # Documentation utilisateur
â””â”€â”€ PROJECT_STRUCTURE.md           # Documentationen techniques complÃ¨te
```

---

## ðŸ“Š COMPARAISON DES 3 APPROCHES

| CritÃ¨re | Approche 1 (Feature) | Approche 3 (Fine-tuning) | Approche 2 (Custom) |
|---------|----------------------|--------------------------|---------------------|
| **Concept** | BERT gelÃ© | BERT modifiÃ© | RÃ©seau custom |
| **EntraÃ®nement** | âŒ ZÃ©ro | âœ… 5-10 min | âœ… 30-60 min |
| **DonnÃ©es** | 100-200 | 500-1000 | 1000-5000 |
| **Performance** | ~82% | ~91% | ~85-90% |
| **Temps/rÃ©ponse** | âš¡ 0.3 sec | 0.5 sec | ðŸ¢ 1-2 sec |
| **MÃ©moire** | 500 MB | 2.5 GB | 3-5 GB |
| **GPU** | âŒ Non | â­ Optionnel | â­ RecommandÃ© |
| **Meilleur pour** | Prototypes | Production | Recherche/custom |
| **FacilitÃ©** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Code** | Simple | ModÃ©rÃ© | Complexe |

---

# ðŸš€ PLAN D'EXÃ‰CUTION - APPROCHE 1 (âœ… COMPLÃ‰TÃ‰E)

**STATUS:** Phase 1-6 terminÃ©es Ã  100%
- âœ… Sentiment Analyzer avec BERT (Feature Extraction)
- âœ… Mood Tracker & Visualizations
- âœ… Response Generator
- âœ… Interface Web & Console
- âœ… 23 tests unitaires passants
- âœ… Documentation complÃ¨te

**NE RIEN MODIFIER dans Approche 1 - elle fonctionne parfaitement!**

---

# ðŸ”¥ PLAN D'EXÃ‰CUTION - APPROCHE 3 : FINE-TUNING BERT (PRIORITAIRE â­)

**CONCEPT CLÃ‰S :**
- Approche 1 : Utiliser BERT comme un dictionnaire gÃ©nÃ©ral
- Approche 3 : SpÃ©cialiser ce dictionnaire pour le bien-Ãªtre

### PHASE 3B : FINE-TUNING BERT (Ã‰tapes 8-12)

#### Ã‰tape 8 : ThÃ©orie du Fine-tuning
**AVANT DE CODER, comprendre :**

1. **Feature Extraction vs Fine-tuning :**
```
Feature Extraction:
Input â†’ [BERT GELÃ‰ â„ï¸] â†’ Features â†’ [Petit classifieur] â†’ RÃ©sultat

Fine-tuning:
Input â†’ [BERT MODIFIABLE ðŸ”¥] â†’ [EntraÃ®nement] â†’ Meilleur rÃ©sultat
```

2. **Comment fonctionne le fine-tuning :**
   - BERT connaÃ®t dÃ©jÃ  la langue franÃ§aise (prÃ©-entraÃ®nÃ©)
   - Nous ajustons les poids pour reconnaÃ®tre les sentiments bien-Ãªtre
   - Learning rate trÃ¨s faible (2e-5) pour ne pas tout casser
   - Early stopping pour Ã©viter l'overfitting

3. **Learning rate :**
   - Feature Extraction : pas d'entraÃ®nement
   - Fine-tuning : 2e-5 (trÃ¨s faible!)
   - Custom : 1e-3 (plus Ã©levÃ©)

4. **Quand utiliser quoi :**
   - Peu de donnÃ©es ? â†’ Approche 1
   - Temps limitÃ© ? â†’ Approche 1
   - DonnÃ©es bien-Ãªtre spÃ©cialisÃ©es ? â†’ Approche 3
   - Besoin ultra-personnalisÃ© ? â†’ Approche 2

**QUESTIONS POUR TOI :**
1. Pourquoi BERT est prÃ©-entraÃ®nÃ© et pas custom ?
2. C'est quoi un gradient et pourquoi c'est important ?
3. Si on met learning_rate=0.1, que se passe-t-il ?
4. Pourquoi l'early stopping est utile ?

---

#### Ã‰tape 9 : DonnÃ©es pour Fine-tuning
**CRÃ‰ER :**
- `src/approach3/data_preparation.py`

**CODE :**
```python
"""
PrÃ©paration des donnÃ©es pour fine-tuning BERT
CrÃ©e un dataset de textes bien-Ãªtre avec labels
"""

import json
import random
from typing import List, Tuple

def create_wellbeing_dataset(size: int = 500) -> List[dict]:
    """
    CrÃ©e un dataset d'entraÃ®nement pour fine-tuning
    
    Args:
        size (int): Nombre total d'exemples
        
    Returns:
        list: Dataset avec structure [{'text': ..., 'label': ...}, ...]
    """
    
    # Exemples par sentiment (Ã  complÃ©ter avec VRAIES donnÃ©es)
    DATASET = {
        'trÃ¨s nÃ©gatif': [
            "Je veux tout abandonner",
            "Je ne vois pas d'issue",
            "Je suis dÃ©sespÃ©rÃ©",
            # Ã€ ajouter 100+ exemples rÃ©els
        ],
        'nÃ©gatif': [
            "Je suis triste",
            "Rien n'a d'importance",
            "Je me sens vide",
            # Ã€ ajouter 100+ exemples
        ],
        'neutre': [
            "Bonjour, comment Ã§a va?",
            "Il fait beau dehors",
            "Quelle heure est-il?",
            # Ã€ ajouter 100+ exemples
        ],
        'positif': [
            "Ã‡a va plutÃ´t bien",
            "J'ai une bonne journÃ©e",
            "Je suis content",
            # Ã€ ajouter 100+ exemples
        ],
        'trÃ¨s positif': [
            "Je suis heureux!",
            "C'est une journÃ©e formidable!",
            "Je me sens vivant et Ã©nergique!",
            # Ã€ ajouter 100+ exemples
        ]
    }
    
    # CrÃ©er le dataset Ã©quilibrÃ©
    dataset = []
    examples_per_class = size // 5  # 5 classes
    
    label_to_id = {
        'trÃ¨s nÃ©gatif': 0,
        'nÃ©gatif': 1,
        'neutre': 2,
        'positif': 3,
        'trÃ¨s positif': 4
    }
    
    for label, texts in DATASET.items():
        # Prendre examples_per_class textes par classe
        selected = random.sample(texts, min(examples_per_class, len(texts)))
        for text in selected:
            dataset.append({
                'text': text,
                'label': label,
                'label_id': label_to_id[label]
            })
    
    # MÃ©langer le dataset
    random.shuffle(dataset)
    
    return dataset


def save_dataset(dataset: List[dict], filepath: str = 'data/training_wellbeing_data.json'):
    """Sauvegarde le dataset en JSON"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)


def load_dataset(filepath: str = 'data/training_wellbeing_data.json') -> List[dict]:
    """Charge le dataset depuis JSON"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)
```

**DEMANDE-MOI :**
1. Comment trouver des donnÃ©es rÃ©elles bien-Ãªtre ?
2. Comment crÃ©er 500 exemples manuellement ?
3. Qu'est-ce qu'un dataset Ã©quilibrÃ© ?

---

#### Ã‰tape 10 : ImplÃ©mentation du Fine-tuner
**CRÃ‰ER :**
- `src/approach3/sentiment_finetuner.py`

**CODE :**
```python
"""
Fine-tuning BERT pour l'analyse de sentiment bien-Ãªtre
"""

import torch
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    Trainer, 
    TrainingArguments
)
from torch.utils.data import Dataset
from typing import List, Dict


class WellbeingDataset(Dataset):
    """Dataset PyTorch pour le fine-tuning de BERT"""
    
    def __init__(self, texts: List[str], labels: List[int], 
                 tokenizer, max_length: int = 128):
        """
        Initialise le dataset
        
        Args:
            texts: Liste de textes
            labels: Liste d'IDs de labels (0-4)
            tokenizer: Tokenizer BERT
            max_length: Longueur max des sÃ©quences
        """
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        """Nombre d'exemples dans le dataset"""
        return len(self.texts)
    
    def __getitem__(self, idx):
        """RÃ©cupÃ¨re un exemple"""
        text = self.texts[idx]
        label = self.labels[idx]
        
        # Tokenize le texte
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',  # Pad toutes les sÃ©quences Ã  max_length
            truncation=True,        # Tronque si trop long
            return_tensors='pt'     # Retourne des tensors PyTorch
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(label, dtype=torch.long)
        }


class BERTFineTuner:
    """Fine-tune BERT pour l'analyse de sentiment"""
    
    def __init__(self, model_name: str = 'bert-base-multilingual-uncased'):
        """
        Initialise le fine-tuner
        
        Args:
            model_name: Nom du modÃ¨le BERT (de HuggingFace)
        """
        print(f"ðŸ”§ Chargement de {model_name}...")
        
        # Charger le tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # Charger le modÃ¨le MODIFIABLE (pas gelÃ©)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=5  # 5 sentiments
        )
        
        print("âœ… ModÃ¨le chargÃ© avec succÃ¨s!")
    
    def train(self, 
              train_texts: List[str], 
              train_labels: List[int],
              val_texts: List[str], 
              val_labels: List[int],
              epochs: int = 3,
              batch_size: int = 8):
        """
        Fine-tune BERT sur nos donnÃ©es
        
        Args:
            train_texts: Textes d'entraÃ®nement
            train_labels: Labels d'entraÃ®nement
            val_texts: Textes de validation
            val_labels: Labels de validation
            epochs: Nombre d'epochs
            batch_size: Taille du batch
        """
        
        print(f"\nðŸ”¥ Fine-tuning sur {len(train_texts)} exemples...")
        
        # CrÃ©er les datasets PyTorch
        train_dataset = WellbeingDataset(
            train_texts, train_labels, 
            self.tokenizer
        )
        val_dataset = WellbeingDataset(
            val_texts, val_labels, 
            self.tokenizer
        )
        
        # Configurer l'entraÃ®nement
        training_args = TrainingArguments(
            output_dir='./models/approach3/bert_finetuned',
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            learning_rate=2e-5,  # ðŸ”‘ TRÃˆS FAIBLE pour fine-tuning
            evaluation_strategy='epoch',
            save_strategy='epoch',
            load_best_model_at_end=True,
            early_stopping_patience=2,  # ArrÃªter si 2 epochs sans amÃ©lioration
            logging_steps=10,
            report_to=['tensorboard']  # Visualiser avec TensorBoard
        )
        
        # CrÃ©er le Trainer
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset
        )
        
        # ðŸš€ ENTRAÃŽNER (modifie les poids de BERT)
        trainer.train()
        
        # Sauvegarder le meilleur modÃ¨le
        trainer.save_model('./models/approach3/bert_finetuned')
        print("âœ… ModÃ¨le sauvegardÃ©!")
    
    def predict(self, text: str) -> Dict:
        """
        Utilise le modÃ¨le pour prÃ©dire le sentiment
        
        Args:
            text: Texte Ã  analyser
            
        Returns:
            dict: Sentiment et confiance
        """
        # Tokenize le texte
        inputs = self.tokenizer(
            text, 
            return_tensors='pt',
            padding=True,
            truncation=True
        )
        
        # PrÃ©dire (sans gradient)
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # RÃ©cupÃ©rer les logits
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)
        
        # Trouver la classe avec la plus haute probabilitÃ©
        predicted_class = torch.argmax(probabilities).item()
        confidence = probabilities[0, predicted_class].item()
        
        # Mapper l'ID au label
        id_to_label = {
            0: 'trÃ¨s nÃ©gatif',
            1: 'nÃ©gatif',
            2: 'neutre',
            3: 'positif',
            4: 'trÃ¨s positif'
        }
        
        return {
            'sentiment': id_to_label[predicted_class],
            'confidence': confidence,
            'all_scores': {
                id_to_label[i]: probabilities[0, i].item()
                for i in range(5)
            }
        }
```

**DEMANDE-MOI :**
1. Explique le rÃ´le de `WellbeingDataset`
2. Pourquoi `learning_rate=2e-5` ?
3. C'est quoi l'early stopping ?

---

#### Ã‰tape 11 : EntraÃ®ner et Tester
**CRÃ‰ER :**
- `src/approach3/train_finetuner.py` (script d'entraÃ®nement)

**CODE COMPLET :**
```python
"""
Script d'entraÃ®nement du fine-tuning BERT
"""

from src.approach3.data_preparation import (
    create_wellbeing_dataset, 
    load_dataset, 
    save_dataset
)
from src.approach3.sentiment_finetuner import BERTFineTuner
from sklearn.model_selection import train_test_split


def main():
    # Ã‰tape 1 : CrÃ©er ou charger le dataset
    print("ðŸ“¥ CrÃ©ation du dataset...")
    dataset = create_wellbeing_dataset(size=500)
    save_dataset(dataset)
    
    # Ã‰tape 2 : Split train/validation (80/20)
    texts = [d['text'] for d in dataset]
    labels = [d['label_id'] for d in dataset]
    
    train_texts, val_texts, train_labels, val_labels = train_test_split(
        texts, labels, test_size=0.2, random_state=42
    )
    
    # Ã‰tape 3 : CrÃ©er le fine-tuner
    finetuner = BERTFineTuner()
    
    # Ã‰tape 4 : EntraÃ®ner
    finetuner.train(
        train_texts, train_labels,
        val_texts, val_labels,
        epochs=3,
        batch_size=8
    )
    
    # Ã‰tape 5 : Tester sur quelques phrases
    test_phrases = [
        "Je suis heureux",
        "Je me sens dÃ©primÃ©",
        "Comment Ã§a va?",
        "Je suis stressÃ© au travail",
        "C'est magnifique!"
    ]
    
    print("\nðŸ“Š RÃ©sultats sur phrases de test:")
    for phrase in test_phrases:
        result = finetuner.predict(phrase)
        print(f"'{phrase}' â†’ {result['sentiment']} ({result['confidence']:.2%})")


if __name__ == '__main__':
    main()
```

**Ã€ EXÃ‰CUTER :**
```bash
python src/approach3/train_finetuner.py
```

---

#### Ã‰tape 12 : Comparaison des Approches
**MODIFIER :**
- `compare_approaches.py`

**AJOUTER :**
```python
def compare_all_approaches():
    """Compare les 3 approches"""
    
    test_phrases = [
        "Je suis heureux",
        "Je me sens stressÃ©",
        "Bonjour",
        "Je ne veux plus continuer",
        "C'est magnifique!"
    ]
    
    # Approche 1 : Feature Extraction
    print("APPROCHE 1 : Feature Extraction")
    from src.approach1.sentiment_analyzer import SentimentAnalyzer
    analyzer1 = SentimentAnalyzer()
    
    # Approche 3 : Fine-tuning
    print("APPROCHE 3 : Fine-tuning BERT")
    from src.approach3.sentiment_analyzer import SentimentAnalyzer as SentimentAnalyzer3
    analyzer3 = SentimentAnalyzer3()
    
    # Comparer
    for phrase in test_phrases:
        result1 = analyzer1.analyze(phrase)
        result3 = analyzer3.analyze(phrase)
        
        print(f"\n'{phrase}'")
        print(f"  Approche 1: {result1['sentiment']} ({result1['confidence']:.2%})")
        print(f"  Approche 3: {result3['sentiment']} ({result3['confidence']:.2%})")
```

---

### PHASE 5B : INTÃ‰GRATION APPROCHE 3 (Ã‰tape 13)

#### Ã‰tape 13 : CrÃ©er Chatbot Approche 3
**CRÃ‰ER :**
- `src/approach3/sentiment_analyzer.py` (charge le modÃ¨le fine-tunÃ©)
- `src/approach3/chatbot.py` (rÃ©utilise mood_tracker & response_generator)

**MODIFIER :**
- `main.py` pour permettre le choix entre Approche 1, 3, et 2

```python
def main():
    print("\nðŸ¤– CHATBOT DE BIEN-ÃŠTRE\n")
    print("Quelle approche utiliser?\n")
    print("1. ðŸš€ Feature Extraction (BERT gelÃ©)")
    print("   â”œâ”€ Rapide (0.3 sec/rÃ©ponse)")
    print("   â”œâ”€ PrÃ©cision: ~82%")
    print("   â””â”€ Pas d'entraÃ®nement")
    print()
    print("2. ðŸ”¥ Fine-tuning BERT (BERT modifiÃ©)")
    print("   â”œâ”€ Ã‰quilibrÃ© (0.5 sec/rÃ©ponse)")
    print("   â”œâ”€ PrÃ©cision: ~91%")
    print("   â””â”€ EntraÃ®nÃ© 5-10 min sur donnÃ©es")
    print()
    print("3. ðŸ§  Custom LSTM/GRU")
    print("   â”œâ”€ Lent (1-2 sec/rÃ©ponse)")
    print("   â”œâ”€ PrÃ©cision: ~85-90%")
    print("   â””â”€ Custom et personnalisable")
    print()
    
    choice = input("Choix (1-3): ").strip()
    
    if choice == '1':
        from src.approach1.chatbot import WellbeingChatbot
        chatbot = WellbeingChatbot()
    elif choice == '2':
        from src.approach3.chatbot import WellbeingChatbot
        chatbot = WellbeingChatbot()
    elif choice == '3':
        from src.approach2.chatbot import WellbeingChatbot
        chatbot = WellbeingChatbot()
    
    chatbot.start()
```

---

## ðŸš€ PLAN D'EXÃ‰CUTION - APPROCHE 2 : CUSTOM LSTM/GRU (Ã€ FAIRE APRÃˆS APPROCHE 3)

### PHASE 7 : PRÃ‰PARATION DES DONNÃ‰ES (Ã‰tape 14-16)

#### Ã‰tape 14 : Comprendre le Deep Learning

(MÃªme structure qu'avant mais avec numÃ©rotation correcte)

---

## âœ… CHECKLIST - ORDRE D'EXÃ‰CUTION

### ACTUELLEMENT EN COURS :
- [ ] Approche 1 - âœ… COMPLÃ‰TÃ‰E
- [ ] Approche 3 (Fine-tuning) - Ã€ COMMENCER
  - [ ] Ã‰tape 8 : ThÃ©orie
  - [ ] Ã‰tape 9 : Data Preparation
  - [ ] Ã‰tape 10 : Fine-tuner
  - [ ] Ã‰tape 11 : EntraÃ®nement
  - [ ] Ã‰tape 12 : Comparaison
  - [ ] Ã‰tape 13 : IntÃ©gration

### ENSUITE :
- [ ] Approche 2 (Custom LSTM)
  - [ ] Ã‰tape 14-16 : Data Prep
  - [ ] Ã‰tape 17-19 : Model Builder
  - [ ] Ã‰tape 20-22 : Training
  - [ ] Ã‰tape 23-25 : Integration

### FINALISATION :
- [ ] Rapport final
- [ ] Soutenance

---

**VERSION:** 2.0 - Mise Ã  jour avec 3 approches distinctes  
**DATE:** 13 Janvier 2026  
**STATUT:** Approche 1 complÃ©tÃ©e, Approche 3 prÃªte Ã  commencer
