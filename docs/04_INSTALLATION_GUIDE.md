# ğŸš€ INSTALLATION & SETUP - Guide Complet

## Vue d'ensemble

Ce guide couvre tout ce qu'il faut pour installer et configurer le chatbot de bien-Ãªtre sur ton systÃ¨me. Nous couvrons Windows, Mac et Linux.

---

## Table des MatiÃ¨res

1. [Installation Rapide](#rapide)
2. [Installation DÃ©taillÃ©e](#detaillee)
3. [TÃ©lÃ©chargement des ModÃ¨les](#modeles)
4. [Configuration GPU (Optionnel)](#gpu)
5. [RÃ©solution de ProblÃ¨mes](#problemes)

---

## Installation Rapide (5 min) {#rapide}

### Windows - MÃ©thode Automatique â­

**Ã‰tape 1: Double-clique `launch_interface.bat`**

C'est tout ! Le script fera automatiquement:
1. CrÃ©er l'environnement virtuel
2. Installer les dÃ©pendances
3. TÃ©lÃ©charger les modÃ¨les
4. Lancer l'interface

### Mac / Linux - MÃ©thode Automatique

```bash
# 1. Clone le projet
git clone <repo_url>
cd "Chatbot bien-Ãªtre"

# 2. ExÃ©cute le script de setup
chmod +x setup.sh
./setup.sh

# 3. Lancer l'interface
python launch_interface.py
```

---

## Installation DÃ©taillÃ©e (15 min) {#detaillee}

### PrÃ©requis SystÃ¨me

**Windows:**
- Python 3.9+ (tÃ©lÃ©charger depuis python.org)
- 4-8 GB RAM minimum
- 3 GB espace disque

**Mac (M1/M2):**
- Python 3.9+ (via Homebrew recommandÃ©)
- 4-8 GB RAM
- 3 GB espace disque
- CommandLineTools: `xcode-select --install`

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install python3.9 python3-pip python3-venv
```

### Ã‰tape 1: Cloner le Projet

```bash
# Via HTTPS
git clone https://github.com/user/chatbot-bien-etre.git
cd "Chatbot bien-Ãªtre"

# Ou via SSH
git clone git@github.com:user/chatbot-bien-etre.git
cd "Chatbot bien-Ãªtre"
```

### Ã‰tape 2: CrÃ©er l'Environnement Virtuel

**Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Mac/Linux:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### Ã‰tape 3: Installer les DÃ©pendances

```bash
# Upgrade pip d'abord
pip install --upgrade pip setuptools wheel

# Installer les requirements
pip install -r requirements.txt
```

**DÃ©pendances principales:**
```
transformers==4.35.2      # BERT
torch==2.1.1              # PyTorch
google-generativeai==0.3.0  # Gemini API
streamlit==1.28.1         # UI
plotly==5.17.0            # Graphiques
pyyaml==6.0               # Config
numpy==1.24.3             # Calculs
pandas==2.0.3             # Data processing
```

### Ã‰tape 4: TÃ©lÃ©charger les ModÃ¨les

```bash
# Option A: Script Python automatique
python download_models.py

# Option B: Depuis Hugging Face manuellement
python scripts/download_models.py
```

â³ **Attendre 10-15 minutes** (premiÃ¨re fois seulement)

### Ã‰tape 5: Configuration API Gemini

**CrÃ©er un fichier `.env`:**
```bash
# Ã€ la racine du projet
echo GOOGLE_API_KEY="ta-clÃ©-api" > .env
```

**Ou modifier `config.yaml`:**
```yaml
google_api_key: "ta-clÃ©-api"
streamlit_port: 8501
```

Obtenir une clÃ© API Gemini:
1. Aller sur [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Cliquer "Create API Key"
3. Copier la clÃ©
4. Ajouter dans `.env` ou `config.yaml`

### Ã‰tape 6: VÃ©rifier l'Installation

```bash
# VÃ©rifier Python
python --version
# Output: Python 3.9+

# VÃ©rifier Streamlit
streamlit --version
# Output: Streamlit, version 1.28+

# VÃ©rifier BERT
python -c "from transformers import AutoModel; print('âœ… Transformers OK')"
# Output: âœ… Transformers OK

# VÃ©rifier Gemini
python -c "import google.generativeai; print('âœ… Gemini OK')"
# Output: âœ… Gemini OK
```

### Ã‰tape 7: Lancer l'Interface

```bash
streamlit run ui/streamlit_app.py
```

ğŸ‰ Le navigateur s'ouvre automatiquement Ã  `http://localhost:8501`

---

## TÃ©lÃ©chargement des ModÃ¨les {#modeles}

### Pourquoi TÃ©lÃ©charger?

Le modÃ¨le BERT fine-tunÃ© est volumineux (638 MB), trop gros pour GitHub. Il est tÃ©lÃ©chargÃ© depuis Hugging Face lors de la premiÃ¨re utilisation.

### ModÃ¨les NÃ©cessaires

```
models/
â”œâ”€â”€ approach3/
â”‚   â””â”€â”€ bert_finetuned/          # BERT fine-tunÃ© (420 MB)
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ pytorch_model.bin    # (ou model.safetensors)
â”‚       â”œâ”€â”€ tokenizer.json
â”‚       â”œâ”€â”€ vocab.txt
â”‚       â””â”€â”€ special_tokens_map.json
â”‚
â””â”€â”€ approach1/                   # (Optionnel - prÃ©-entraÃ®nÃ©)
    â””â”€â”€ bert_pretrained/         # TÃ©lÃ©chargÃ© automatiquement
```

### TÃ©lÃ©chargement Automatique

```python
# download_models.py
from transformers import BertTokenizer, BertForSequenceClassification

# BERT fine-tuned
model = BertForSequenceClassification.from_pretrained(
    "path/to/bert_finetuned",
    local_files_only=False
)
model.save_pretrained("models/approach3/bert_finetuned/")

# Tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-multilingual-cased")
tokenizer.save_pretrained("models/approach3/bert_finetuned/")
```

### TÃ©lÃ©chargement Manuel

```bash
# Si l'auto-tÃ©lÃ©chargement Ã©choue
cd models/approach3

# TÃ©lÃ©charger depuis Hugging Face
git clone https://huggingface.co/bert-base-multilingual-cased

# Ou via curl
curl -L -o bert_finetuned.zip <URL>
unzip bert_finetuned.zip
```

### VÃ©rifier le TÃ©lÃ©chargement

```bash
# VÃ©rifier la structure
ls models/approach3/bert_finetuned/
# Output: config.json pytorch_model.bin tokenizer.json vocab.txt ...

# Ou en Python
import os
assert os.path.exists("models/approach3/bert_finetuned/config.json")
assert os.path.exists("models/approach3/bert_finetuned/pytorch_model.bin")
print("âœ… ModÃ¨les vÃ©rifiÃ©s")
```

**Espace disque utilisÃ©:**
- ModÃ¨le BERT: 420 MB
- Tokenizer: 231 MB
- Total: ~650 MB

---

## Configuration GPU (Optionnel) {#gpu}

### Pourquoi GPU?

- **CPU:** 80-100ms par analyse (acceptable)
- **GPU:** 20-30ms par analyse (optimal)

Pour le fine-tuning de BERT, GPU est recommandÃ©.

### NVIDIA GPU Setup

**PrÃ©requis:**
- GPU NVIDIA (pas AMD/Intel)
- CUDA 11.8 ou 12.1

**Installation CUDA:**

```bash
# 1. TÃ©lÃ©charger CUDA
# https://developer.nvidia.com/cuda-downloads

# 2. Installer cuDNN
# https://developer.nvidia.com/cudnn

# 3. VÃ©rifier l'installation
nvidia-smi
# Output: CUDA Version: 12.1, Driver Version: 535.x

# 4. Installer PyTorch avec CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**VÃ©rifier PyTorch utilise GPU:**

```python
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
print(f"GPU: {torch.cuda.get_device_name(0)}")

# Output:
# CUDA Available: True
# CUDA Version: 12.1
# GPU: NVIDIA GeForce RTX 3090
```

### Google Colab (GPU Gratuit)

Pour fine-tuning sans GPU local:

```python
# Dans notebook Colab
!pip install -r requirements.txt
!python src/approach3/train_finetuner.py

# RÃ©sultats: 3 min d'entraÃ®nement sur T4 GPU gratuit
```

### AMD GPU Setup (MacOS M1/M2)

```bash
# Metal acceleration (automatique)
# PyTorch utilise Metal Framework sur Mac M1/M2

pip install torch torchvision torchaudio
# Fonctionne avec acceleration GPU automatiquement
```

---

## RÃ©solution de ProblÃ¨mes {#problemes}

### âŒ "ModuleNotFoundError: No module named 'streamlit'"

**Cause:** Environnement virtuel pas activÃ© ou pip install incomplet

**Solution:**
```bash
# 1. VÃ©rifier activation
which python  # Mac/Linux: devrait Ãªtre dans .venv/bin/
where python  # Windows: devrait Ãªtre dans .venv\Scripts\

# 2. RÃ©installer
pip install --upgrade pip
pip install -r requirements.txt

# 3. VÃ©rifier
python -c "import streamlit; print(streamlit.__version__)"
```

### âŒ "python: No such file or directory"

**Cause:** Python non installÃ© ou pas dans PATH

**Solution Windows:**
1. DÃ©sinstaller Python complÃ¨tement
2. RÃ©installer depuis python.org
3. **IMPORTANT:** Cocher "Add Python to PATH" pendant l'installation
4. RedÃ©marrer l'ordinateur

**Solution Mac:**
```bash
# Installer via Homebrew
brew install python3.11
# VÃ©rifier
python3 --version
```

### âŒ "Permission denied" ou "Access denied"

**Cause:** Manque de droits administrateur

**Solution Windows:**
- Clic droit sur `launch_interface.bat`
- "ExÃ©cuter en tant qu'administrateur"

**Solution Mac/Linux:**
```bash
sudo chown -R $USER:$USER .
chmod +x *.sh
```

### âŒ "Port 8501 already in use"

**Cause:** Un autre processus Streamlit est actif

**Solution:**
```bash
# Option 1: Utiliser un autre port
streamlit run ui/streamlit_app.py --server.port 8502

# Option 2: Tuer le processus (Linux/Mac)
lsof -i :8501
kill -9 <PID>

# Option 2: Tuer le processus (Windows)
netstat -ano | findstr :8501
taskkill /PID <PID> /F
```

### âŒ "CUDA out of memory" ou erreur GPU

**Cause:** RAM GPU insuffisante

**Solution:**
```python
# Forcer CPU au lieu de GPU
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# Ou rÃ©duire batch size
model = load_model(device='cpu')
```

### âŒ "Connection timeout" lors du tÃ©lÃ©chargement des modÃ¨les

**Cause:** Connexion internet lente ou serveur HF indisponible

**Solution:**
```bash
# Augmenter le timeout
pip install --default-timeout=1000 transformers

# RÃ©essayer
python download_models.py
```

### âŒ ModÃ¨les ne tÃ©lÃ©chargent pas

**Cause:** Stockage plein ou permissions

**Solution:**
```bash
# VÃ©rifier l'espace disque
# Windows: dir
# Linux/Mac: df -h

# VÃ©rifier les permissions
chmod 755 models/
chmod 755 models/approach3/

# TÃ©lÃ©charger manuellement depuis Hugging Face
# https://huggingface.co/models
```

### âŒ Streamlit s'arrÃªte immÃ©diatement

**Cause:** Erreur d'import ou configuration

**Solution:**
```bash
# 1. Lancer en debug
streamlit run ui/streamlit_app.py --logger.level=debug

# 2. VÃ©rifier les imports
python -c "from src.approach3.sentiment_analyzer import SentimentAnalyzer"

# 3. VÃ©rifier la config
cat config.yaml
```

---

## VÃ©rification ComplÃ¨te

```bash
# Script de diagnostic
python -c "
import sys
print(f'Python: {sys.version}')

import streamlit; print(f'Streamlit: {streamlit.__version__}')
import torch; print(f'PyTorch: {torch.__version__}')
import transformers; print(f'Transformers: {transformers.__version__}')
import plotly; print(f'Plotly: {plotly.__version__}')

import google.generativeai; print('Google Generative AI: OK')
from src.cbt_engine import CBTEngine; print('CBT Engine: OK')
print('âœ… All dependencies OK')
"
```

---

## Structure Post-Installation

AprÃ¨s installation complÃ¨te:

```
Chatbot bien-Ãªtre/
â”œâ”€â”€ .venv/                         # Environnement virtuel
â”œâ”€â”€ models/
â”‚   â””â”€â”€ approach3/
â”‚       â””â”€â”€ bert_finetuned/        # âœ… TÃ©lÃ©chargÃ© (650 MB)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mood_history.json          # âœ… CrÃ©Ã© automatiquement
â”‚   â”œâ”€â”€ training_wellbeing_data.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cbt_engine.py
â”‚   â”œâ”€â”€ gemini_wrapper.py
â”‚   â”œâ”€â”€ approach3/
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py
â”‚   â”‚   â”œâ”€â”€ response_generator.py
â”‚   â”‚   â”œâ”€â”€ mood_tracker.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ streamlit_app.py           # âœ… Interface principale
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env                           # âœ… ClÃ© API Gemini
â”œâ”€â”€ config.yaml                    # âœ… Configuration
â”œâ”€â”€ requirements.txt               # âœ… DÃ©pendances
â”œâ”€â”€ launch_interface.bat (Windows)
â””â”€â”€ launch_interface.py (Mac/Linux)
```

---

## Prochaines Ã‰tapes

âœ… **Installation terminÃ©e!**

Maintenant tu peux:

1. **Lancer l'interface:**
   ```bash
   streamlit run ui/streamlit_app.py
   ```

2. **Essayer un message:**
   - Clique sur une phrase rapide
   - Observe la rÃ©ponse et les stats

3. **Explorer les features:**
   - Distorsions CBT dÃ©tectÃ©es
   - Historique d'humeur
   - Graphiques en temps rÃ©el

4. **(Optionnel) Fine-tuner le modÃ¨le:**
   ```bash
   python src/approach3/train_finetuner.py
   # Ou via Colab notebook: notebooks/02_finetuning_bert_gpu.ipynb
   ```

---

## Support

Si tu rencontres un problÃ¨me:

1. VÃ©rifier la section "RÃ©solution de ProblÃ¨mes" ci-dessus
2. Consulter les logs: `streamlit run ui/streamlit_app.py --logger.level=debug`
3. VÃ©rifier l'issue sur GitHub
4. Ouvrir une nouvelle issue avec les dÃ©tails

---

**DerniÃ¨re mise Ã  jour:** 17 janvier 2026
**Status:** âœ… Installation SimplifiÃ©e & TestÃ©e
