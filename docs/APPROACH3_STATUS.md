# ğŸ”¥ Approche 3 : Fine-tuning BERT - Guide Complet

## ğŸ“Š Vue d'ensemble

| Aspect | DÃ©tail |
|--------|--------|
| **Status** | âœ… Code complet - EntraÃ®nement GPU disponible |
| **ModÃ¨le** | BERT multilingual fine-tunÃ© |
| **Dataset** | 500 exemples bien-Ãªtre (5 classes) |
| **EntraÃ®nement** | 3 epochs, learning rate 2e-5 |
| **DurÃ©e** | 2-3 min (GPU) ou 10-15 min (CPU) |
| **PrÃ©cision attendue** | 91-95% |

---

## ğŸ¯ Concept

**Fine-tuning = SpÃ©cialiser BERT pour le bien-Ãªtre**

```
Avant fine-tuning:
Input: "Je me sens vide"
BERT (gÃ©nÃ©ral) â†’ "nÃ©gatif" (confiance: 75%)

AprÃ¨s fine-tuning:
Input: "Je me sens vide"
BERT (spÃ©cialisÃ©) â†’ "trÃ¨s nÃ©gatif - dÃ©pression" (confiance: 93%)
```

**DiffÃ©rence avec Approche 1 :**

| Aspect | Approche 1 (Feature Extraction) | Approche 3 (Fine-tuning) |
|--------|--------------------------------|--------------------------|
| **BERT** | â„ï¸ GelÃ© (poids fixes) | ğŸ”¥ Modifiable (poids ajustÃ©s) |
| **EntraÃ®nement** | âŒ Aucun | âœ… 3 epochs sur donnÃ©es bien-Ãªtre |
| **Learning rate** | N/A | 2e-5 (trÃ¨s faible) |
| **Temps** | 0 sec | 2-3 min (GPU) |
| **PrÃ©cision** | ~82% | ~91-95% |
| **SpÃ©cialisation** | GÃ©nÃ©rique | Bien-Ãªtre spÃ©cifique |

---

## ğŸ“ Fichiers crÃ©Ã©s

### 1. Dataset et prÃ©paration

**`src/approach3/data_preparation.py`**
- CrÃ©ation de 500 exemples bien-Ãªtre
- 5 classes Ã©quilibrÃ©es (100 par classe)
- Split train/validation (80/20)
- Sauvegarde JSON

```python
from src.approach3.data_preparation import create_wellbeing_dataset

dataset = create_wellbeing_dataset(500)
# RÃ©sultat: 500 exemples Ã©quilibrÃ©s
```

### 2. Fine-tuner BERT

**`src/approach3/sentiment_finetuner.py`**
- Classe `WellbeingDataset` (PyTorch)
- Classe `BERTFineTuner`
- MÃ©thodes : `train()`, `predict()`

```python
from src.approach3.sentiment_finetuner import BERTFineTuner

finetuner = BERTFineTuner()
finetuner.train(train_texts, train_labels, val_texts, val_labels, epochs=3)
```

### 3. Script d'entraÃ®nement

**`src/approach3/train_finetuner.py`**
- Script complet d'entraÃ®nement
- Chargement dataset
- EntraÃ®nement BERT
- Tests

```bash
python src/approach3/train_finetuner.py
```

### 4. Analyseur fine-tunÃ©

**`src/approach3/sentiment_analyzer.py`**
- Charge le modÃ¨le fine-tunÃ©
- API compatible avec Approche 1
- MÃ©thode `analyze(text)`

```python
from src.approach3.sentiment_analyzer import SentimentAnalyzer

analyzer = SentimentAnalyzer()
result = analyzer.analyze("Je suis heureux")
# {'sentiment': 'trÃ¨s positif', 'confidence': 0.94}
```

### 5. Chatbot Approche 3

**`src/approach3/chatbot.py`**
- RÃ©utilise mood_tracker d'Approche 1
- RÃ©utilise response_generator d'Approche 1
- Utilise sentiment_analyzer fine-tunÃ©

```python
from src.approach3.chatbot import WellbeingChatbot

bot = WellbeingChatbot()
bot.start_conversation()
```

### 6. Notebook GPU

**`notebooks/02_finetuning_bert_gpu.ipynb`**
- Notebook pour Google Colab
- EntraÃ®nement sur GPU T4
- TÃ©lÃ©chargement du modÃ¨le

---

## ğŸš€ EntraÃ®nement sur GPU (RECOMMANDÃ‰)

### Option 1 : Google Colab â­

**Pourquoi Colab ?**
- âœ… GPU T4 gratuit
- âœ… 15 GB VRAM
- âœ… Pas d'installation locale
- âœ… EntraÃ®nement 2-3 minutes

**Ã‰tapes :**

1. **Ouvrir Colab**
   - https://colab.research.google.com/

2. **Upload notebook**
   - `File` â†’ `Upload notebook`
   - SÃ©lectionner `notebooks/02_finetuning_bert_gpu.ipynb`

3. **Activer GPU** âš¡
   - `Runtime` â†’ `Change runtime type`
   - `Hardware accelerator` â†’ **T4 GPU**
   - `Save`

4. **ExÃ©cuter**
   - `Runtime` â†’ `Run all`
   - Attendre 2-3 minutes

5. **TÃ©lÃ©charger**
   ```python
   !zip -r bert_finetuned_final.zip bert_finetuned_final/
   ```
   - Clic droit â†’ Download

6. **Installer localement**
   - Extraire `bert_finetuned_final.zip`
   - Copier dans `models/approach3/bert_finetuned/`

### Option 2 : Kaggle

**Avantages :**
- 30h/semaine de GPU (vs 12h/jour Colab)
- GPU T4 ou P100

**Ã‰tapes :**
1. CrÃ©er compte : https://www.kaggle.com/
2. `Notebooks` â†’ `New Notebook`
3. Settings â†’ `Accelerator` â†’ **GPU T4**
4. Copier-coller le code
5. Run all

---

## ğŸ’» EntraÃ®nement local (CPU)

**Si vous n'avez pas accÃ¨s Ã  un GPU :**

```bash
cd "C:\Users\LOQ\Documents\Chatbot bien-Ãªtre"
python src/approach3/train_finetuner.py
```

â³ **DurÃ©e : 10-15 minutes**

**Configuration actuelle :**
- 1 epoch (rÃ©duit pour CPU)
- Batch size 16
- Learning rate 2e-5

---

## ğŸ“Š Dataset

### Structure

```json
{
  "text": "Je suis heureux!",
  "label": "trÃ¨s positif",
  "label_id": 4
}
```

### 5 Classes de sentiment

| ID | Label | Exemples | Count |
|----|-------|----------|-------|
| 0 | TrÃ¨s nÃ©gatif | "Je veux tout abandonner" | 100 |
| 1 | NÃ©gatif | "Je suis triste" | 100 |
| 2 | Neutre | "Bonjour, comment Ã§a va?" | 100 |
| 3 | Positif | "Ã‡a va bien" | 100 |
| 4 | TrÃ¨s positif | "Je suis heureux!" | 100 |

**Total : 500 exemples Ã©quilibrÃ©s**

### Split

- **Train** : 400 exemples (80%)
- **Validation** : 100 exemples (20%)

---

## âš™ï¸ HyperparamÃ¨tres

| ParamÃ¨tre | Valeur | Explication |
|-----------|--------|-------------|
| **Learning rate** | 2e-5 | Standard pour fine-tuning BERT |
| **Epochs** | 3 | Bon compromis (GPU) ou 1 (CPU) |
| **Batch size** | 16 (GPU) / 8 (CPU) | Selon mÃ©moire disponible |
| **Weight decay** | 0.01 | RÃ©gularisation L2 |
| **Max length** | 128 | Longueur max tokens |
| **Optimizer** | AdamW | Optimizer standard |

---

## ğŸ“ˆ RÃ©sultats attendus

### Training loss

| Epoch | Loss | Temps (GPU) |
|-------|------|-------------|
| 1 | ~1.2 | 50 sec |
| 2 | ~0.6 | 50 sec |
| 3 | ~0.4 | 50 sec |

### Validation loss

| Epoch | Loss | Accuracy |
|-------|------|----------|
| 1 | ~0.8 | ~75% |
| 2 | ~0.5 | ~85% |
| 3 | ~0.4 | ~91-95% |

### Comparaison avec Approche 1

| MÃ©trique | Approche 1 | Approche 3 |
|----------|------------|------------|
| **Accuracy** | 82% | 91-95% |
| **Temps/rÃ©ponse** | 0.3 sec | 0.5 sec |
| **Confiance** | 75% | 92% |
| **SpÃ©cialisation** | GÃ©nÃ©rique | Bien-Ãªtre |

---

## ğŸ§ª Tests

### Test du modÃ¨le fine-tunÃ©

```bash
python compare_approaches.py
```

**RÃ©sultat attendu :**
```
ğŸ“Š COMPARAISON : APPROCHE 1 vs APPROCHE 3
=================================================================

ğŸŸ¢ APPROCHE 1 : FEATURE EXTRACTION
   'Je suis heureux!'       â†’ positif    (74.3%)
   'Je me sens dÃ©primÃ©'     â†’ nÃ©gatif    (40.5%)
   ...

ğŸ”¥ APPROCHE 3 : FINE-TUNING
   'Je suis heureux!'       â†’ trÃ¨s positif (94.2%)
   'Je me sens dÃ©primÃ©'     â†’ trÃ¨s nÃ©gatif (91.7%)
   ...

ğŸ“Š RÃ‰SUMÃ‰ COMPARATIF
Total de tests: 8
Accord Approche 1/3: 6/8 (75.0%)
âœ… Rapport sauvegardÃ©: data/comparison_report.json
```

### Test du chatbot

```bash
python -c "from src.approach3.chatbot import WellbeingChatbot; bot = WellbeingChatbot(); bot.start_conversation()"
```

---

## ğŸ¯ Prochaines Ã©tapes

AprÃ¨s avoir entraÃ®nÃ© Approche 3 :

1. âœ… **Comparer avec Approche 1**
   ```bash
   python compare_approaches.py
   ```

2. âœ… **Tester le chatbot**
   ```bash
   python src/approach3/chatbot.py
   ```

3. âœ… **Interface Streamlit** (TODO)
   - Modifier `ui/streamlit_ui.py`
   - Ajouter option Approche 3

4. âœ… **Approche 2** (Custom LSTM)
   - Commencer Approche 2
   - Comparer les 3 approches

5. âœ… **Rapport final**
   - RÃ©diger le rapport
   - Comparaison complÃ¨te
   - PrÃ©sentation

---

## ğŸ“š Ressources

- **Guide GPU** : [docs/GPU_TRAINING_GUIDE.md](GPU_TRAINING_GUIDE.md)
- **Notebook Colab** : `notebooks/02_finetuning_bert_gpu.ipynb`
- **HuggingFace Transformers** : https://huggingface.co/docs/transformers/
- **BERT Paper** : https://arxiv.org/abs/1810.04805

---

## âœ… Checklist

- [x] Code Approche 3 complet
- [x] Dataset 500 exemples crÃ©Ã©
- [x] Fine-tuner implÃ©mentÃ©
- [x] Script d'entraÃ®nement prÃªt
- [x] Notebook GPU crÃ©Ã©
- [ ] ModÃ¨le entraÃ®nÃ© sur GPU
- [ ] ModÃ¨le tÃ©lÃ©chargÃ© localement
- [ ] Tests avec compare_approaches.py
- [ ] Chatbot Approche 3 testÃ©
- [ ] Rapport de comparaison gÃ©nÃ©rÃ©

---

**Date de crÃ©ation** : 14 janvier 2026  
**Status** : âœ… PrÃªt pour entraÃ®nement GPU  
**Prochaine Ã©tape** : EntraÃ®ner sur Google Colab
