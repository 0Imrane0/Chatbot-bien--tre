"""
Module d'Analyse de Sentiment - Approche 1 (Transfer Learning)
Utilise un mod√®le BERT pr√©-entra√Æn√© pour analyser le sentiment des messages

Auteur : √âtudiant ENSA Berrechid
Date : D√©cembre 2024
"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
from typing import Dict, Any
import yaml


class SentimentAnalyzer:
    """
    Analyseur de sentiment bas√© sur BERT multilingue
    
    Ce mod√®le peut analyser des textes en fran√ßais, anglais, arabe et autres langues.
    Il retourne un sentiment (positif/n√©gatif/neutre) avec un score de confiance.
    
    Architecture :
    - Tokenizer : D√©coupe le texte en tokens (morceaux)
    - Mod√®le BERT : Analyse le sentiment
    - Softmax : Convertit les scores en probabilit√©s
    """
    
    def __init__(self, config_path: str = None):
        """
        Initialise l'analyseur de sentiment
        
        Args:
            config_path (str): Chemin vers le fichier config.yaml
                              Si None, utilise la config par d√©faut
        
        √âtapes d'initialisation :
        1. Charger la configuration
        2. Charger le tokenizer (d√©coupage des mots)
        3. Charger le mod√®le BERT pr√©-entra√Æn√©
        4. D√©finir le mapping des labels
        """
        print("üîß Initialisation de l'analyseur de sentiment...")
        
        # √âtape 1 : Charger la configuration
        if config_path:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                self.config = config['approach1']
        else:
            # Configuration par d√©faut si pas de fichier
            self.config = {
                'model_name': 'nlptown/bert-base-multilingual-uncased-sentiment',
                'max_length': 512,
                'confidence_threshold': 0.6
            }
        
        # √âtape 2 : Charger le tokenizer
        # Le tokenizer d√©coupe le texte en tokens (morceaux)
        # Exemple : "Je suis content" ‚Üí ["Je", "suis", "content"]
        print(f"üì• Chargement du tokenizer : {self.config['model_name']}")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.config['model_name']
        )
        
        # √âtape 3 : Charger le mod√®le BERT pr√©-entra√Æn√©
        # Ce mod√®le a d√©j√† √©t√© entra√Æn√© sur des millions de textes !
        print(f"üì• Chargement du mod√®le BERT...")
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.config['model_name']
        )
        
        # Mettre le mod√®le en mode √©valuation (pas d'entra√Ænement)
        self.model.eval()
        
        # √âtape 4 : D√©finir le mapping des labels
        # Le mod√®le retourne des chiffres (0-4), on les convertit en sentiments
        self.label_mapping = {
            0: 'tr√®s n√©gatif',
            1: 'n√©gatif',
            2: 'neutre',
            3: 'positif',
            4: 'tr√®s positif'
        }
        
        # Simplification en 3 cat√©gories principales
        self.simplified_mapping = {
            0: 'n√©gatif',
            1: 'n√©gatif',
            2: 'neutre',
            3: 'positif',
            4: 'positif'
        }
        
        print("‚úÖ Analyseur de sentiment pr√™t !\n")
    
    def analyze(self, text: str) -> Dict[str, Any]:
        """
        Analyse le sentiment d'un texte
        
        Args:
            text (str): Le texte √† analyser (peut √™tre en FR, EN, AR, etc.)
        
        Returns:
            dict: Dictionnaire contenant :
                - sentiment (str): 'positif', 'n√©gatif', ou 'neutre'
                - sentiment_detail (str): Version d√©taill√©e (ex: 'tr√®s positif')
                - confidence (float): Score de confiance (0-1)
                - confidence_percent (float): Score en pourcentage (0-100)
                - all_scores (dict): Tous les scores pour chaque cat√©gorie
                - text_length (int): Longueur du texte analys√©
        
        Processus :
        1. Tokenization : D√©couper le texte
        2. Conversion en tenseurs PyTorch
        3. Passage dans le mod√®le BERT
        4. Softmax pour obtenir des probabilit√©s
        5. Interpr√©tation des r√©sultats
        """
        # Validation de l'entr√©e
        if not text or not text.strip():
            return {
                'sentiment': 'neutre',
                'sentiment_detail': 'neutre',
                'confidence': 0.0,
                'confidence_percent': 0.0,
                'all_scores': {},
                'text_length': 0,
                'error': 'Texte vide'
            }
        
        # √âtape 1 : TOKENIZATION
        # D√©couper le texte en tokens que BERT peut comprendre
        # padding=True : Ajoute des tokens sp√©ciaux pour atteindre max_length
        # truncation=True : Coupe le texte s'il est trop long
        # return_tensors='pt' : Retourne des tenseurs PyTorch
        inputs = self.tokenizer(
            text,
            padding=True,
            truncation=True,
            max_length=self.config['max_length'],
            return_tensors='pt'  # 'pt' = PyTorch tensors
        )
        
        # √âtape 2 : PR√âDICTION avec BERT
        # torch.no_grad() : D√©sactive le calcul des gradients (on n'entra√Æne pas)
        # √âconomise de la m√©moire et acc√©l√®re le calcul
        with torch.no_grad():
            # Passer les tokens dans le mod√®le BERT
            outputs = self.model(**inputs)
            
            # R√©cup√©rer les logits (scores bruts avant softmax)
            logits = outputs.logits
            
            # √âtape 3 : SOFTMAX
            # Convertir les logits en probabilit√©s qui somment √† 1
            # Exemple : [-2.1, 0.5, 3.2] ‚Üí [0.01, 0.12, 0.87]
            probabilities = torch.softmax(logits, dim=1)
            
            # √âtape 4 : TROUVER LA PR√âDICTION
            # torch.argmax : Trouve l'indice du score maximum
            predicted_class = torch.argmax(probabilities, dim=1).item()
            
            # R√©cup√©rer le score de confiance pour cette pr√©diction
            confidence = probabilities[0][predicted_class].item()
        
        # √âtape 5 : FORMATER LES R√âSULTATS
        
        # Cr√©er un dictionnaire avec tous les scores
        all_scores = {}
        for i, label in self.label_mapping.items():
            all_scores[label] = float(probabilities[0][i].item())
        
        # R√©cup√©rer le sentiment d√©taill√© et simplifi√©
        sentiment_detail = self.label_mapping[predicted_class]
        sentiment_simple = self.simplified_mapping[predicted_class]
        
        # Construire le r√©sultat final
        result = {
            'sentiment': sentiment_simple,
            'sentiment_detail': sentiment_detail,
            'confidence': round(confidence, 3),
            'confidence_percent': round(confidence * 100, 1),
            'all_scores': all_scores,
            'text_length': len(text),
            'predicted_class': predicted_class
        }
        
        return result
    
    def analyze_batch(self, texts: list) -> list:
        """
        Analyse plusieurs textes en m√™me temps (plus efficace)
        
        Args:
            texts (list): Liste de textes √† analyser
        
        Returns:
            list: Liste de dictionnaires de r√©sultats
        """
        results = []
        for text in texts:
            results.append(self.analyze(text))
        return results
    
    def get_emotion_interpretation(self, result: Dict[str, Any]) -> str:
        """
        G√©n√®re une interpr√©tation textuelle du sentiment
        
        Args:
            result (dict): R√©sultat de la m√©thode analyze()
        
        Returns:
            str: Interpr√©tation en langage naturel
        """
        sentiment = result['sentiment']
        confidence = result['confidence_percent']
        
        # Interpr√©tations selon le sentiment et la confiance
        if sentiment == 'positif':
            if confidence > 80:
                return "Tu sembles vraiment de bonne humeur ! üòä"
            elif confidence > 60:
                return "Tu as l'air plut√¥t positif aujourd'hui üôÇ"
            else:
                return "Il y a une touche de positivit√© dans ton message"
        
        elif sentiment == 'n√©gatif':
            if confidence > 80:
                return "Je sens que tu traverses un moment difficile üòî"
            elif confidence > 60:
                return "Tu n'as pas l'air dans ton assiette..."
            else:
                return "Il y a une petite nuance n√©gative"
        
        else:  # neutre
            return "Ton message est plut√¥t neutre, ni tr√®s positif ni n√©gatif"
    
    def is_confident(self, result: Dict[str, Any]) -> bool:
        """
        V√©rifie si l'analyse est suffisamment confiante
        
        Args:
            result (dict): R√©sultat de la m√©thode analyze()
        
        Returns:
            bool: True si la confiance d√©passe le seuil
        """
        threshold = self.config['confidence_threshold']
        return result['confidence'] >= threshold


# ============================================
# FONCTION DE TEST / D√âMO
# ============================================

def demo():
    """
    Fonction de d√©monstration de l'analyseur de sentiment
    Teste avec diff√©rentes phrases en fran√ßais
    """
    print("=" * 60)
    print("ü§ñ D√âMONSTRATION - ANALYSEUR DE SENTIMENT")
    print("=" * 60)
    print()
    
    # Cr√©er l'analyseur
    analyzer = SentimentAnalyzer()
    
    # Phrases de test
    test_phrases = [
        "Je suis vraiment heureux aujourd'hui !",
        "Je me sens triste et seul...",
        "Le temps est nuageux",
        "Je d√©teste tout √ßa, c'est horrible",
        "C'√©tait une journ√©e normale, ni bien ni mal",
        "J'adore cette application, elle est g√©niale ! üòä",
        "Je ne sais pas quoi faire, je suis perdu",
        "La vie est belle",
        "Je suis malade et fatigu√©",    
        "C'est mieux que jamais"
    ]
    
    # Analyser chaque phrase
    for i, phrase in enumerate(test_phrases, 1):
        print(f"\nüìù Test {i} : \"{phrase}\"")
        print("-" * 60)
        
        result = analyzer.analyze(phrase)
        
        print(f"   Sentiment : {result['sentiment'].upper()} ({result['sentiment_detail']})")
        print(f"   Confiance : {result['confidence_percent']}%")
        print(f"   Interpr√©tation : {analyzer.get_emotion_interpretation(result)}")
        print(f"   Fiable ? {'‚úÖ Oui' if analyzer.is_confident(result) else '‚ö†Ô∏è Incertain'}")
        
        # Afficher tous les scores
        print(f"\n   D√©tail des scores :")
        for label, score in result['all_scores'].items():
            bar_length = int(score * 30)
            bar = "‚ñà" * bar_length
            print(f"      {label:15} : {bar} {score*100:.1f}%")
    
    print("\n" + "=" * 60)
    print("‚úÖ D√©monstration termin√©e !")
    print("=" * 60)


# Point d'entr√©e si on ex√©cute ce fichier directement
if __name__ == "__main__":
    demo()
