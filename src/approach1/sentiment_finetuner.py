"""
ğŸ¯ Fine-tuning de BERT pour l'Analyse de Sentiment - Approche 1 bis
====================================================================

Ce module implÃ©mente le FINE-TUNING de BERT sur des donnÃ©es
spÃ©cifiques au bien-Ãªtre mental.

DiffÃ©rence avec l'approche actuelle (Feature Extraction) :
- Feature Extraction : On utilise BERT tel quel (poids gelÃ©s)
- Fine-tuning : On rÃ©entraÃ®ne BERT sur nos donnÃ©es (poids modifiables)

Avantages du Fine-tuning :
âœ… Meilleure prÃ©cision sur notre domaine
âœ… Comprend le vocabulaire spÃ©cifique (bien-Ãªtre, anxiÃ©tÃ©, etc.)
âœ… S'adapte aux nuances de notre contexte

InconvÃ©nients :
âŒ NÃ©cessite des donnÃ©es d'entraÃ®nement (500+ exemples)
âŒ Plus lent (1-3h d'entraÃ®nement)
âŒ Besoin de GPU (recommandÃ©)

Auteur : Ã‰tudiant ENSA Berrechid
Module : Programmation Python et IA
"""

import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback
)
from torch.utils.data import Dataset
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple
import os
from datetime import datetime


# ============================================================
# DATASET PERSONNALISÃ‰
# ============================================================

class WellbeingDataset(Dataset):
    """
    Dataset PyTorch pour le fine-tuning BERT.
    
    PrÃ©pare les donnÃ©es dans le format attendu par le Trainer.
    
    Structure :
    - Textes : Les messages utilisateur
    - Labels : Les sentiments (0=trÃ¨s nÃ©gatif, 4=trÃ¨s positif)
    - Tokenization : Conversion en tokens BERT
    """
    
    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):
        """
        Initialise le dataset.
        
        Args:
            texts: Liste des textes Ã  classifier
            labels: Liste des labels (0-4)
            tokenizer: Tokenizer BERT
            max_length: Longueur maximale des sÃ©quences
        """
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        """Retourne le nombre d'exemples."""
        return len(self.texts)
    
    def __getitem__(self, idx):
        """
        Retourne un exemple tokenisÃ©.
        
        Process :
        1. Prendre le texte et le label
        2. Tokeniser le texte
        3. Retourner au format attendu par BERT
        """
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        # Tokenization avec padding et truncation
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        # Retourner un dictionnaire
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }


# ============================================================
# CLASSE PRINCIPALE DE FINE-TUNING
# ============================================================

class BERTFineTuner:
    """
    Classe pour fine-tuner BERT sur des donnÃ©es de bien-Ãªtre mental.
    
    FonctionnalitÃ©s :
    - Charger un modÃ¨le BERT de base
    - Fine-tuner sur des donnÃ©es custom
    - Sauvegarder et charger le modÃ¨le ajustÃ©
    - Ã‰valuer les performances
    - Comparer avec Feature Extraction
    """
    
    def __init__(self, 
                 model_name: str = 'bert-base-multilingual-uncased',
                 num_labels: int = 5,
                 output_dir: str = './models/finetuned'):
        """
        Initialise le fine-tuner.
        
        Args:
            model_name: Nom du modÃ¨le de base Ã  fine-tuner
            num_labels: Nombre de classes (5 sentiments)
            output_dir: Dossier de sauvegarde
        """
        print("ğŸ”§ Initialisation du Fine-Tuner BERT...")
        print(f"   ğŸ“¦ ModÃ¨le de base : {model_name}")
        print(f"   ğŸ¯ Nombre de classes : {num_labels}")
        
        self.model_name = model_name
        self.num_labels = num_labels
        self.output_dir = output_dir
        
        # Charger le tokenizer
        print("ğŸ“¥ Chargement du tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # Charger le modÃ¨le
        print("ğŸ“¥ Chargement du modÃ¨le BERT...")
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_labels
        )
        
        # VÃ©rifier si GPU disponible
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"   ğŸ’» Device : {self.device}")
        
        if self.device.type == 'cpu':
            print("   âš ï¸  Pas de GPU dÃ©tectÃ© - L'entraÃ®nement sera plus lent")
        else:
            print("   âœ… GPU disponible - EntraÃ®nement rapide !")
        
        self.model.to(self.device)
        
        print("âœ… Fine-Tuner prÃªt !\n")
    
    def prepare_data(self, 
                     texts: List[str], 
                     labels: List[int],
                     val_split: float = 0.2) -> Tuple[Dataset, Dataset]:
        """
        PrÃ©pare les donnÃ©es pour l'entraÃ®nement.
        
        Args:
            texts: Liste des textes
            labels: Liste des labels
            val_split: Proportion pour validation (0.2 = 20%)
        
        Returns:
            train_dataset, val_dataset
        
        Process :
        1. Convertir les labels texte en numÃ©rique si besoin
        2. Split train/validation
        3. CrÃ©er les datasets PyTorch
        """
        print(f"ğŸ“Š PrÃ©paration des donnÃ©es...")
        print(f"   â€¢ Total exemples : {len(texts)}")
        
        # MÃ©langer les donnÃ©es
        indices = np.random.permutation(len(texts))
        texts = [texts[i] for i in indices]
        labels = [labels[i] for i in indices]
        
        # Split train/val
        split_idx = int(len(texts) * (1 - val_split))
        
        train_texts = texts[:split_idx]
        train_labels = labels[:split_idx]
        
        val_texts = texts[split_idx:]
        val_labels = labels[split_idx:]
        
        print(f"   â€¢ EntraÃ®nement : {len(train_texts)}")
        print(f"   â€¢ Validation : {len(val_texts)}")
        
        # CrÃ©er les datasets
        train_dataset = WellbeingDataset(train_texts, train_labels, self.tokenizer)
        val_dataset = WellbeingDataset(val_texts, val_labels, self.tokenizer)
        
        print("âœ… DonnÃ©es prÃ©parÃ©es !\n")
        
        return train_dataset, val_dataset
    
    def train(self,
              train_dataset: Dataset,
              val_dataset: Dataset,
              epochs: int = 3,
              batch_size: int = 8,
              learning_rate: float = 2e-5,
              warmup_steps: int = 500):
        """
        Fine-tune le modÃ¨le sur les donnÃ©es.
        
        Args:
            train_dataset: Dataset d'entraÃ®nement
            val_dataset: Dataset de validation
            epochs: Nombre d'epochs
            batch_size: Taille du batch
            learning_rate: Taux d'apprentissage
            warmup_steps: Ã‰tapes de warmup
        
        Process :
        1. Configurer les arguments d'entraÃ®nement
        2. CrÃ©er le Trainer
        3. Lancer le fine-tuning
        4. Sauvegarder le modÃ¨le
        """
        print("=" * 60)
        print("ğŸ¯ DÃ‰BUT DU FINE-TUNING")
        print("=" * 60)
        print(f"\nâš™ï¸  Configuration :")
        print(f"   â€¢ Epochs : {epochs}")
        print(f"   â€¢ Batch size : {batch_size}")
        print(f"   â€¢ Learning rate : {learning_rate}")
        print(f"   â€¢ Warmup steps : {warmup_steps}")
        print(f"   â€¢ Device : {self.device}")
        print()
        
        # Configuration de l'entraÃ®nement
        training_args = TrainingArguments(
            output_dir=self.output_dir,
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            learning_rate=learning_rate,
            warmup_steps=warmup_steps,
            weight_decay=0.01,
            logging_dir=f'{self.output_dir}/logs',
            logging_steps=10,
            evaluation_strategy='epoch',
            save_strategy='epoch',
            load_best_model_at_end=True,
            metric_for_best_model='eval_loss',
            greater_is_better=False,
            save_total_limit=2,  # Garder seulement les 2 meilleurs modÃ¨les
            report_to='none'  # DÃ©sactiver wandb, tensorboard, etc.
        )
        
        # CrÃ©er le Trainer
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
        )
        
        # ğŸ”¥ FINE-TUNING - Les poids de BERT changent !
        print("ğŸš€ Lancement de l'entraÃ®nement...\n")
        start_time = datetime.now()
        
        train_result = trainer.train()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n" + "=" * 60)
        print("âœ… FINE-TUNING TERMINÃ‰ !")
        print("=" * 60)
        print(f"â±ï¸  DurÃ©e totale : {duration/60:.2f} minutes")
        print(f"ğŸ“ˆ Loss finale : {train_result.training_loss:.4f}")
        
        # Sauvegarder le modÃ¨le
        print(f"\nğŸ’¾ Sauvegarde du modÃ¨le dans {self.output_dir}...")
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        
        print("âœ… ModÃ¨le sauvegardÃ© !")
        print()
        
        return trainer
    
    def evaluate(self, val_dataset: Dataset) -> Dict:
        """
        Ã‰value le modÃ¨le fine-tunÃ©.
        
        Args:
            val_dataset: Dataset de validation
        
        Returns:
            MÃ©triques d'Ã©valuation
        """
        print("ğŸ“Š Ã‰valuation du modÃ¨le...\n")
        
        # CrÃ©er un trainer pour l'Ã©valuation
        trainer = Trainer(
            model=self.model,
            eval_dataset=val_dataset
        )
        
        # Ã‰valuer
        metrics = trainer.evaluate()
        
        print("ğŸ“ˆ RÃ©sultats :")
        for key, value in metrics.items():
            print(f"   â€¢ {key}: {value:.4f}")
        
        return metrics
    
    def load_finetuned_model(self, model_path: str):
        """
        Charge un modÃ¨le dÃ©jÃ  fine-tunÃ©.
        
        Args:
            model_path: Chemin vers le modÃ¨le sauvegardÃ©
        """
        print(f"ğŸ“¥ Chargement du modÃ¨le fine-tunÃ© depuis {model_path}...")
        
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model.to(self.device)
        
        print("âœ… ModÃ¨le chargÃ© !")
    
    def predict(self, text: str) -> Dict:
        """
        Fait une prÃ©diction avec le modÃ¨le fine-tunÃ©.
        
        Args:
            text: Texte Ã  analyser
        
        Returns:
            Dictionnaire avec sentiment et confiance
        """
        # Tokeniser
        inputs = self.tokenizer(
            text,
            return_tensors='pt',
            max_length=128,
            padding='max_length',
            truncation=True
        )
        
        # DÃ©placer sur le bon device
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # PrÃ©diction
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # InterprÃ©ter les rÃ©sultats
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0][predicted_class].item()
        
        # Mapping des labels
        sentiment_map = {
            0: 'trÃ¨s nÃ©gatif',
            1: 'nÃ©gatif',
            2: 'neutre',
            3: 'positif',
            4: 'trÃ¨s positif'
        }
        
        return {
            'sentiment': sentiment_map[predicted_class],
            'predicted_class': predicted_class,
            'confidence': confidence,
            'all_scores': probs[0].cpu().numpy().tolist()
        }


# ============================================================
# FONCTIONS UTILITAIRES
# ============================================================

def create_sample_dataset() -> Tuple[List[str], List[int]]:
    """
    CrÃ©e un dataset d'exemple pour tester le fine-tuning.
    
    En production, tu devrais :
    - Collecter de vraies donnÃ©es
    - Annoter manuellement
    - Utiliser des datasets publics
    
    Returns:
        texts, labels
    """
    print("ğŸ“ CrÃ©ation d'un dataset d'exemple...\n")
    
    # Dataset d'exemple sur le bien-Ãªtre mental
    data = [
        # TrÃ¨s positif (4)
        ("Je me sens incroyablement bien aujourd'hui !", 4),
        ("Quelle joie de vivre, je suis Ã©panoui !", 4),
        ("J'ai rÃ©ussi Ã  surmonter mon anxiÃ©tÃ©, je suis fier !", 4),
        ("La thÃ©rapie m'aide Ã©normÃ©ment, je vais beaucoup mieux !", 4),
        ("Je suis en paix avec moi-mÃªme, c'est merveilleux !", 4),
        
        # Positif (3)
        ("Je me sens bien, Ã§a va mieux qu'hier", 3),
        ("La mÃ©ditation m'aide Ã  me relaxer", 3),
        ("J'ai passÃ© une bonne journÃ©e, je suis content", 3),
        ("Je commence Ã  voir du positif dans ma vie", 3),
        ("Mes proches me soutiennent beaucoup", 3),
        
        # Neutre (2)
        ("Je suis allÃ© me promener aujourd'hui", 2),
        ("J'ai lu un livre sur la psychologie", 2),
        ("Il fait beau dehors", 2),
        ("J'ai pris mes mÃ©dicaments ce matin", 2),
        ("J'ai rendez-vous chez le mÃ©decin demain", 2),
        
        # NÃ©gatif (1)
        ("Je me sens stressÃ© par le travail", 1),
        ("J'ai du mal Ã  dormir ces derniers temps", 1),
        ("L'anxiÃ©tÃ© revient souvent", 1),
        ("Je me sens fatiguÃ© et dÃ©motivÃ©", 1),
        ("C'est difficile en ce moment", 1),
        
        # TrÃ¨s nÃ©gatif (0)
        ("Je me sens complÃ¨tement dÃ©sespÃ©rÃ©", 0),
        ("Je n'arrive plus Ã  gÃ©rer mon anxiÃ©tÃ©", 0),
        ("Je me sens seul et incompris", 0),
        ("Rien ne va, je suis au bout du rouleau", 0),
        ("Je n'ai plus d'Ã©nergie pour continuer", 0),
    ]
    
    texts = [item[0] for item in data]
    labels = [item[1] for item in data]
    
    print(f"âœ… Dataset crÃ©Ã© : {len(texts)} exemples")
    print(f"   â€¢ Distribution des classes :")
    for i in range(5):
        count = labels.count(i)
        print(f"     - Classe {i}: {count} exemples")
    print()
    
    return texts, labels


# ============================================================
# SCRIPT D'EXEMPLE
# ============================================================

def main():
    """
    Script d'exemple pour le fine-tuning.
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ FINE-TUNING DE BERT POUR LE BIEN-ÃŠTRE MENTAL")
    print("=" * 60)
    print()
    
    # 1. CrÃ©er des donnÃ©es d'exemple
    texts, labels = create_sample_dataset()
    
    # 2. Initialiser le fine-tuner
    finetuner = BERTFineTuner(
        model_name='bert-base-multilingual-uncased',
        num_labels=5,
        output_dir='./models/finetuned_wellbeing'
    )
    
    # 3. PrÃ©parer les donnÃ©es
    train_dataset, val_dataset = finetuner.prepare_data(texts, labels, val_split=0.2)
    
    # 4. Fine-tuner le modÃ¨le
    trainer = finetuner.train(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        epochs=3,
        batch_size=4,  # Petit batch pour CPU
        learning_rate=2e-5
    )
    
    # 5. Ã‰valuer
    metrics = finetuner.evaluate(val_dataset)
    
    # 6. Tester quelques prÃ©dictions
    print("\n" + "=" * 60)
    print("ğŸ§ª TESTS DE PRÃ‰DICTION")
    print("=" * 60)
    print()
    
    test_phrases = [
        "Je me sens vraiment bien aujourd'hui !",
        "Je suis anxieux pour mon avenir",
        "Il fait beau"
    ]
    
    for phrase in test_phrases:
        result = finetuner.predict(phrase)
        print(f"ğŸ“ \"{phrase}\"")
        print(f"   â†’ {result['sentiment']} ({result['confidence']:.2%})")
        print()
    
    print("âœ… Fine-tuning terminÃ© avec succÃ¨s !")
    print(f"ğŸ’¾ ModÃ¨le sauvegardÃ© dans : ./models/finetuned_wellbeing")


if __name__ == "__main__":
    main()
