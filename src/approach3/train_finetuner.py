"""
Script d'entraÃ®nement du fine-tuning BERT
Lance l'entraÃ®nement complet : prÃ©paration â†’ fine-tuning â†’ sauvegarde
"""

import sys
from pathlib import Path

# Ajouter le rÃ©pertoire parent au path pour importer nos modules
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.approach3.data_preparation import (
    load_dataset,
    split_train_val,
    validate_dataset
)
from src.approach3.sentiment_finetuner import BERTFineTuner


def main():
    """Lance le processus complet d'entraÃ®nement"""
    
    print("\n" + "=" * 70)
    print("ğŸ”¥ FINE-TUNING BERT POUR L'ANALYSE DE SENTIMENT BIEN-ÃŠTRE")
    print("=" * 70)
    
    # ============================================================================
    # Ã‰TAPE 1 : Charger le dataset
    # ============================================================================
    
    print("\nğŸ“¥ Ã‰TAPE 1 : Chargement du dataset...")
    try:
        dataset = load_dataset('data/training_wellbeing_data.json')
    except FileNotFoundError:
        print("âŒ Dataset non trouvÃ©! CrÃ©er le dataset d'abord:")
        print("   python src/approach3/data_preparation.py")
        return
    
    # ============================================================================
    # Ã‰TAPE 2 : Valider le dataset
    # ============================================================================
    
    print("\nâœ… Ã‰TAPE 2 : Validation du dataset...")
    validate_dataset(dataset)
    
    # ============================================================================
    # Ã‰TAPE 3 : Split train/validation
    # ============================================================================
    
    print("\nğŸ“Š Ã‰TAPE 3 : Split train/validation...")
    train_dataset, val_dataset = split_train_val(dataset, train_ratio=0.8)
    
    # Extraire textes et labels
    train_texts = [d['text'] for d in train_dataset]
    train_labels = [d['label_id'] for d in train_dataset]
    
    val_texts = [d['text'] for d in val_dataset]
    val_labels = [d['label_id'] for d in val_dataset]
    
    # ============================================================================
    # Ã‰TAPE 4 : CrÃ©er le fine-tuner
    # ============================================================================
    
    print("\nğŸ¤– Ã‰TAPE 4 : Initialisation du fine-tuner...")
    finetuner = BERTFineTuner(
        model_name='bert-base-multilingual-uncased',
        output_dir='models/approach3/bert_finetuned'
    )
    
    # ============================================================================
    # Ã‰TAPE 5 : Fine-tuner BERT
    # ============================================================================
    
    print("\nğŸ”¥ Ã‰TAPE 5 : Fine-tuning BERT...")
    print("   â±ï¸  DurÃ©e estimÃ©e: 5-10 minutes (CPU) ou 1-2 minutes (GPU)")
    
    trainer = finetuner.train(
        train_texts=train_texts,
        train_labels=train_labels,
        val_texts=val_texts,
        val_labels=val_labels,
        epochs=1,              # RÃ©duit Ã  1 epoch pour viter les problÃ¨mes CPU
        batch_size=16,         # Augmenter batch size pour plus d'efficacitÃ©
        learning_rate=2e-5     # 2e-5 = standard pour fine-tuning BERT
    )
    
    # ============================================================================
    # Ã‰TAPE 6 : Tester le modÃ¨le fine-tunÃ©
    # ============================================================================
    
    print("\nğŸ§ª Ã‰TAPE 6 : Test du modÃ¨le fine-tunÃ©...")
    print("=" * 70)
    
    test_phrases = [
        "Je suis heureux!",
        "Je me sens dÃ©primÃ©",
        "Comment Ã§a va?",
        "Je ne veux plus continuer",
        "C'est magnifique!",
        "Je suis trÃ¨s stressÃ©",
        "Tout va bien",
        "Je suis dÃ©sespÃ©rÃ©",
    ]
    
    print("\nğŸ“Š PrÃ©dictions:")
    print("-" * 70)
    
    for phrase in test_phrases:
        result = finetuner.predict(phrase)
        sentiment = result['sentiment']
        confidence = result['confidence']
        
        # Format couleur (emoji)
        emoji_map = {
            'trÃ¨s nÃ©gatif': 'ğŸ”´',
            'nÃ©gatif': 'ğŸŸ ',
            'neutre': 'ğŸŸ¡',
            'positif': 'ğŸŸ¢',
            'trÃ¨s positif': 'ğŸŸ¢ğŸŸ¢'
        }
        emoji = emoji_map.get(sentiment, 'âšª')
        
        print(f"{emoji} '{phrase}'")
        print(f"   â†’ {sentiment:15s} ({confidence:.1%})")
    
    # ============================================================================
    # Ã‰TAPE 7 : RÃ©sumÃ© et prochaines Ã©tapes
    # ============================================================================
    
    print("\n" + "=" * 70)
    print("âœ… FINE-TUNING COMPLÃ‰TÃ‰!")
    print("=" * 70)
    print(f"\nğŸ“ ModÃ¨le sauvegardÃ© : models/approach3/bert_finetuned/")
    print("\nğŸ¯ Prochaines Ã©tapes:")
    print("   1. Comparer Approche 1 vs Approche 3")
    print("   2. IntÃ©grer le modÃ¨le fine-tunÃ© dans le chatbot")
    print("   3. Lancer Approche 2 (Custom LSTM)")


if __name__ == '__main__':
    main()
