"""
ü§ñ Gemini API Wrapper - G√©n√©ration de R√©ponses Personnalis√©es
==============================================================

Utilise Gemini 1.5 Flash pour g√©n√©rer des r√©ponses empathiques et personnalis√©es
bas√©es sur le sentiment d√©tect√© par BERT.

Architecture Hybrid:
- BERT (Approach 3) ‚Üí Analyse sentiment (100% pr√©cis, < 100ms)
- Gemini API ‚Üí G√©n√®re r√©ponse personnalis√©e (contextuelle, ~2s)

Auteur: √âtudiant ENSA Berrechid
Date: Janvier 2026
"""

from google import genai
from google.genai import types
from typing import Dict, List, Optional
import json
from datetime import datetime

class GeminiChatbot:
    """
    Wrapper pour Gemini API - G√©n√©ration de r√©ponses th√©rapeutiques
    """
    
    def __init__(self, api_key: str):
        """
        Initialise le client Gemini
        
        Args:
            api_key: Cl√© API Google Gemini
        """
        self.api_key = api_key
        
        # Nouveau client Gemini (nouvelle biblioth√®que)
        self.client = genai.Client(api_key=self.api_key)
        self.model_name = 'gemini-2.5-flash'  # Mod√®le rapide et performant
        
        # Configuration de g√©n√©ration
        self.generation_config = types.GenerateContentConfig(
            temperature=0.8,  # Cr√©ativit√© mod√©r√©e
            top_p=0.95,
            top_k=40,
            max_output_tokens=500,
        )
        
        # Prompt syst√®me - Guide le comportement de Gemini
        self.system_prompt = self._create_system_prompt()
        
        print("‚úÖ Gemini API configur√© et pr√™t (nouvelle version)!")
    
    def _create_system_prompt(self) -> str:
        """
        Cr√©e le prompt syst√®me qui guide Gemini
        
        Returns:
            str: Prompt syst√®me complet
        """
        return """Tu es un assistant de bien-√™tre empathique et bienveillant. Ton r√¥le est d'√©couter, comprendre et soutenir les utilisateurs dans leurs √©motions.

R√àGLES IMPORTANTES:
1. R√©ponds TOUJOURS en fran√ßais
2. Sois empathique et chaleureux
3. Adapte ton ton au sentiment d√©tect√©:
   - Tr√®s n√©gatif/Crise: S√©rieux, pr√©occup√©, propose aide imm√©diate
   - N√©gatif: Compr√©hensif, encourageant, sugg√®re des actions
   - Neutre: Amical, ouvert, pose des questions pour comprendre
   - Positif: Enthousiaste, partage la joie
   - Tr√®s positif: C√©l√®bre avec l'utilisateur
4. Utilise des emojis appropri√©s (maximum 2-3)
5. Garde les r√©ponses concises (2-4 phrases)
6. Ne donne JAMAIS de diagnostic m√©dical
7. Si crise d√©tect√©e, oriente vers aide professionnelle

CONTEXTE:
Tu as acc√®s √†:
- Le message de l'utilisateur
- Le sentiment d√©tect√© par IA (tr√®s n√©gatif, n√©gatif, neutre, positif, tr√®s positif)
- La confiance de la d√©tection (0-100%)
- L'historique r√©cent de l'humeur

G√©n√®re une r√©ponse personnalis√©e qui montre que tu comprends et que tu es l√† pour aider."""
    
    def generate_response(
        self,
        user_message: str,
        sentiment: str,
        sentiment_detail: str,
        confidence: float,
        mood_trend: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict:
        """
        G√©n√®re une r√©ponse personnalis√©e via Gemini
        
        Args:
            user_message: Message de l'utilisateur
            sentiment: Sentiment g√©n√©ral (positif/n√©gatif/neutre)
            sentiment_detail: Sentiment d√©taill√© (tr√®s n√©gatif, n√©gatif, etc.)
            confidence: Confiance de la d√©tection (0-1)
            mood_trend: Tendance d'humeur sur 7 jours (optionnel)
            conversation_history: Historique r√©cent (optionnel)
        
        Returns:
            dict: {
                'response': str,           # R√©ponse g√©n√©r√©e
                'is_crisis': bool,         # Crise d√©tect√©e ?
                'fallback_used': bool,     # Fallback utilis√© ?
                'generation_time': float   # Temps de g√©n√©ration
            }
        """
        start_time = datetime.now()
        
        # D√©tecter situation de crise
        is_crisis = self._is_crisis(user_message, sentiment_detail)
        
        # Construire le contexte pour Gemini
        context = self._build_context(
            user_message=user_message,
            sentiment=sentiment,
            sentiment_detail=sentiment_detail,
            confidence=confidence,
            mood_trend=mood_trend,
            conversation_history=conversation_history,
            is_crisis=is_crisis
        )
        
        try:
            # Appel √† Gemini avec la NOUVELLE API
            full_prompt = f"{self.system_prompt}\n\n{context}"
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_prompt,
                config=self.generation_config
            )
            
            generated_text = response.text.strip()
            
            # Temps de g√©n√©ration
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'response': generated_text,
                'is_crisis': is_crisis,
                'fallback_used': False,
                'generation_time': generation_time,
                'sentiment_used': sentiment_detail,
                'confidence': confidence
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur Gemini API: {e}")
            
            # Fallback: Utiliser un template simple
            fallback_response = self._get_fallback_response(sentiment_detail, is_crisis)
            
            generation_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'response': fallback_response,
                'is_crisis': is_crisis,
                'fallback_used': True,
                'generation_time': generation_time,
                'error': str(e)
            }
    
    def _build_context(
        self,
        user_message: str,
        sentiment: str,
        sentiment_detail: str,
        confidence: float,
        mood_trend: Optional[Dict],
        conversation_history: Optional[List[Dict]],
        is_crisis: bool
    ) -> str:
        """
        Construit le contexte pour Gemini
        
        Returns:
            str: Contexte format√©
        """
        context_parts = []
        
        # Message utilisateur
        context_parts.append(f"MESSAGE UTILISATEUR:\n\"{user_message}\"")
        
        # Sentiment d√©tect√©
        context_parts.append(f"\nSENTIMENT D√âTECT√â:")
        context_parts.append(f"- Cat√©gorie: {sentiment_detail}")
        context_parts.append(f"- Confiance: {confidence*100:.0f}%")
        
        if is_crisis:
            context_parts.append("- ‚ö†Ô∏è ALERTE CRISE: Mots-cl√©s critiques d√©tect√©s (suicide, etc.)")
        
        # Tendance d'humeur
        if mood_trend:
            trend_value = mood_trend.get('trend', 0)
            if trend_value > 0.2:
                context_parts.append(f"\nTENDANCE: Am√©lioration r√©cente (+{trend_value:.1f})")
            elif trend_value < -0.2:
                context_parts.append(f"\nTENDANCE: D√©t√©rioration r√©cente ({trend_value:.1f})")
            else:
                context_parts.append(f"\nTENDANCE: Stable")
        
        # Historique r√©cent (optionnel)
        if conversation_history and len(conversation_history) > 0:
            context_parts.append("\nHISTORIQUE R√âCENT:")
            for msg in conversation_history[-3:]:  # 3 derniers messages
                role = "Utilisateur" if msg.get('role') == 'user' else "Bot"
                content = msg.get('content', '')[:100]  # Limiter √† 100 chars
                context_parts.append(f"- {role}: {content}")
        
        # Instruction de g√©n√©ration
        context_parts.append("\nG√âN√àRE UNE R√âPONSE:")
        if is_crisis:
            context_parts.append("- Montre une pr√©occupation imm√©diate")
            context_parts.append("- Propose des ressources d'urgence")
            context_parts.append("- Encourage √† chercher aide professionnelle")
        else:
            context_parts.append("- Empathique et personnalis√©e")
            context_parts.append("- Adapt√©e au sentiment d√©tect√©")
            context_parts.append("- Concise (2-4 phrases)")
        
        return "\n".join(context_parts)
    
    def _is_crisis(self, message: str, sentiment: str) -> bool:
        """
        D√©tecte si c'est une situation de crise
        
        Args:
            message: Message utilisateur
            sentiment: Sentiment d√©tect√©
        
        Returns:
            bool: True si crise d√©tect√©e
        """
        crisis_keywords = [
            'suicide', 'suicider', 'tuer', 'mourir', 'en finir',
            'disparaitre', 'plus rien', 'sans espoir', 'ne peux plus',
            'abandonner', 'partir', 'fin'
        ]
        
        message_lower = message.lower()
        
        # V√©rifier mots-cl√©s
        for keyword in crisis_keywords:
            if keyword in message_lower:
                return True
        
        # Si tr√®s n√©gatif avec forte confiance
        if sentiment == 'tr√®s n√©gatif':
            return True
        
        return False
    
    def _get_fallback_response(self, sentiment: str, is_crisis: bool) -> str:
        """
        G√©n√®re une r√©ponse de fallback si Gemini √©choue
        
        Args:
            sentiment: Sentiment d√©tect√©
            is_crisis: Si crise d√©tect√©e
        
        Returns:
            str: R√©ponse de fallback
        """
        if is_crisis:
            return ("Je suis vraiment inquiet pour toi. üòü "
                    "S'il te pla√Æt, contacte imm√©diatement une ligne d'urgence. "
                    "Tu n'es pas seul(e), et il y a des gens qui peuvent t'aider. üÜò")
        
        fallback_templates = {
            'tr√®s n√©gatif': "Je vois que tu traverses une p√©riode tr√®s difficile. üíô Je suis l√† pour t'√©couter.",
            'n√©gatif': "Je comprends que ce soit dur en ce moment. üòî Veux-tu en parler ?",
            'neutre': "Je suis l√† pour toi. Comment te sens-tu vraiment ? ü§ó",
            'positif': "C'est bien de te voir dans un meilleur √©tat ! üòä Qu'est-ce qui te rend heureux ?",
            'tr√®s positif': "Wow, c'est g√©nial ! üéâ Je suis content pour toi !"
        }
        
        return fallback_templates.get(sentiment, "Je suis l√† pour t'√©couter. üíô")
    
    def get_cbt_analysis(
        self,
        user_message: str,
        sentiment: str
    ) -> Dict:
        """
        Analyse CBT via Gemini (optionnel)
        
        Args:
            user_message: Message utilisateur
            sentiment: Sentiment d√©tect√©
        
        Returns:
            dict: Analyse CBT
        """
        if sentiment not in ['n√©gatif', 'tr√®s n√©gatif']:
            return {'distortions': [], 'restructuring': None}
        
        cbt_prompt = f"""{self.system_prompt}

MESSAGE UTILISATEUR:
"{user_message}"

T√ÇCHE: Identifie les distorsions cognitives pr√©sentes (catastrophisation, tout-ou-rien, surg√©n√©ralisation, lecture de pens√©es, raisonnement √©motionnel).

R√©ponds en JSON:
{{
    "distortions": ["nom distorsion 1", "nom distorsion 2"],
    "restructuring": "Pens√©e alternative plus √©quilibr√©e"
}}
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=cbt_prompt,
                config=self.generation_config
            )
            result_text = response.text.strip()
            
            # Parser JSON
            if '```json' in result_text:
                result_text = result_text.split('```json')[1].split('```')[0].strip()
            elif '```' in result_text:
                result_text = result_text.split('```')[1].split('```')[0].strip()
            
            cbt_data = json.loads(result_text)
            return cbt_data
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur CBT Analysis: {e}")
            return {'distortions': [], 'restructuring': None}


# ============================================================
# FONCTION HELPER POUR TESTER
# ============================================================

def test_gemini():
    """Test rapide de Gemini API"""
    api_key = "AIzaSyA_KawZtJbvfRP_mtL4glFPIMWsFxGgi68"
    
    gemini = GeminiChatbot(api_key)
    
    test_cases = [
        ("Je me sens compl√®tement nul", "tr√®s n√©gatif", 0.95),
        ("Je suis un peu stress√©", "n√©gatif", 0.85),
        ("J'ai r√©ussi mon examen!", "tr√®s positif", 0.95)
    ]
    
    print("\n" + "="*60)
    print("üß™ TEST GEMINI API")
    print("="*60)
    
    for msg, sentiment, confidence in test_cases:
        print(f"\nüìù Message: '{msg}'")
        print(f"   Sentiment: {sentiment} ({confidence*100:.0f}%)")
        
        result = gemini.generate_response(
            user_message=msg,
            sentiment=sentiment.split()[0] if ' ' in sentiment else sentiment,
            sentiment_detail=sentiment,
            confidence=confidence
        )
        
        print(f"   ü§ñ R√©ponse: {result['response']}")
        print(f"   ‚è±Ô∏è  Temps: {result['generation_time']:.2f}s")
        print(f"   üîÑ Fallback: {result['fallback_used']}")


if __name__ == "__main__":
    test_gemini()
